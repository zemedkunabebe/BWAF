{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d448044-d0db-495d-9be0-0f512125976a",
   "metadata": {},
   "source": [
    "# **Baseline Model: Replication of msBERT-Promoter**\n",
    "\n",
    "**Objective:**\n",
    "This notebook implements a baseline model inspired by the core concepts of \"msBERT-Promoter\" (Li et al., 2024), focusing on the promoter identification task. It features:\n",
    "1.  Multi-scale k-mer tokenization (k=3, 4, 5, 6).\n",
    "2.  Training individual Transformer-based models for each k-mer, with **epoch-level checkpointing and resuming capability**.\n",
    "3.  The main loop **skips k-mer models that have already completed training** (unless forced by `force_kmer_model_rebuild`).\n",
    "4.  Ensembling predictions using soft voting.\n",
    "\n",
    "This baseline is trained on the same data splits as the main proposed model for fair comparison.\n",
    "\n",
    "---\n",
    "\n",
    "## **0. Setup and Imports**\n",
    "This cell imports all required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ce12c9b-18a6-40a3-9ce6-d859850dfa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful.\n",
      "PyTorch Version: 2.7.0+cu126\n"
     ]
    }
   ],
   "source": [
    "# %% 0. Setup and Imports\n",
    "# ============================================================================\n",
    "# Standard library imports\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import gzip\n",
    "import time\n",
    "import argparse\n",
    "import datetime\n",
    "import sys\n",
    "import warnings\n",
    "import random\n",
    "import traceback # <<< IMPORT TRACEBACK HERE\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split # For splitting indices\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                           f1_score, roc_auc_score, confusion_matrix)\n",
    "from tqdm.notebook import tqdm # Use notebook version for Jupyter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.DtypeWarning)\n",
    "\n",
    "print(\"Imports successful.\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc312ec1-f828-4a03-84f7-03792a33e3d4",
   "metadata": {},
   "source": [
    "## **1. Configuration / Constants (for msBERT-Promoter Replication)**\n",
    "Defines paths, model hyperparameters, and training settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e8c675f-6f6c-4d42-b6fc-1f92a8c2ee15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-mer Replication: Using device: cpu\n",
      "K-mer Replication: Output directory: results_msBERT_replication\n"
     ]
    }
   ],
   "source": [
    "# %% 1. Configuration / Constants for msBERT-Promoter Replication\n",
    "# ============================================================================\n",
    "# --- Data Paths ---\n",
    "BASE_DATA_DIR_REPLICATION = './data/'\n",
    "SEQ_DATA_DIR_REPLICATION = os.path.join(BASE_DATA_DIR_REPLICATION, 'raw/human_genome_annotation')\n",
    "OUTPUT_DIR_MSBERT_REPLICATION = 'results_msBERT_replication'\n",
    "\n",
    "PROMOTER_SEQ_FILE_REPLICATION = os.path.join(SEQ_DATA_DIR_REPLICATION, 'updated_promoter_features_clean.csv')\n",
    "NON_PROMOTER_SEQ_FILE_REPLICATION = os.path.join(SEQ_DATA_DIR_REPLICATION, 'updated_non_promoter_sequences.csv')\n",
    "\n",
    "# --- K-mer Model Specific Hyperparameters ---\n",
    "KMER_VALUES = [3, 4, 5, 6]\n",
    "KMER_STRIDE = 1\n",
    "SEQ_LEN_FOR_KMER_LOADING = 2000\n",
    "\n",
    "KMER_EMBED_DIM = 64\n",
    "KMER_NUM_HEADS = 4\n",
    "KMER_NUM_TRANSFORMER_LAYERS = 2\n",
    "KMER_TRANSFORMER_FF_DIM = KMER_EMBED_DIM * 4\n",
    "KMER_DROPOUT_RATE = 0.1\n",
    "\n",
    "# --- Training Hyperparameters ---\n",
    "LEARNING_RATE_KMER = 0.0001\n",
    "BATCH_SIZE_KMER = 32\n",
    "NUM_EPOCHS_KMER = 10\n",
    "VALIDATION_SPLIT = 0.15\n",
    "TEST_SPLIT = 0.15\n",
    "RANDOM_SEED = 42\n",
    "OPTIMIZER_WEIGHT_DECAY_KMER = 1e-5\n",
    "\n",
    "# --- Output Files ---\n",
    "os.makedirs(OUTPUT_DIR_MSBERT_REPLICATION, exist_ok=True)\n",
    "KMER_MODEL_BEST_SAVE_PATH_TPL = os.path.join(OUTPUT_DIR_MSBERT_REPLICATION, 'best_kmer_model_k{k}.pth')\n",
    "KMER_CHECKPOINT_DIR_TPL = os.path.join(OUTPUT_DIR_MSBERT_REPLICATION, \"checkpoints_k{k}\")\n",
    "KMER_LOSS_PLOT_PATH_TPL = os.path.join(OUTPUT_DIR_MSBERT_REPLICATION, 'loss_kmer_k{k}.png')\n",
    "ENSEMBLE_RESULTS_CSV_PATH = os.path.join(OUTPUT_DIR_MSBERT_REPLICATION, 'test_results_kmer_ensemble.csv')\n",
    "ENSEMBLE_CM_PLOT_PATH_BASE = os.path.join(OUTPUT_DIR_MSBERT_REPLICATION, 'confusion_matrix_kmer_ensemble')\n",
    "LOG_FILE_PATH_KMER = os.path.join(OUTPUT_DIR_MSBERT_REPLICATION, 'training_log_kmer_baseline.txt')\n",
    "\n",
    "# --- Hardware ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Setup ---\n",
    "random.seed(RANDOM_SEED); np.random.seed(RANDOM_SEED); torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "print(f\"K-mer Replication: Using device: {DEVICE}\")\n",
    "print(f\"K-mer Replication: Output directory: {OUTPUT_DIR_MSBERT_REPLICATION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdca7ee3-57a2-4e23-9084-48fe28bd4a51",
   "metadata": {},
   "source": [
    "## **2. Utility Functions (for K-mer Processing)**\n",
    "Helper functions for logging, k-mer tokenization, vocabulary building, numericalizing k-mer sequences, and loading raw DNA sequences for this baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4126d09b-9dae-4a92-8f91-1da43a353203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-19 13:18:59] K-mer Baseline Log started at: results_msBERT_replication/training_log_kmer_baseline.txt\n",
      "[2025-06-19 13:18:59] Using device: cpu for k-mer operations.\n"
     ]
    }
   ],
   "source": [
    "# %% 2. Utility Functions (for K-mer Processing)\n",
    "# ============================================================================\n",
    "def log_message_kmer(message, log_file=LOG_FILE_PATH_KMER):\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    full_message = f\"[{timestamp}] {message}\"\n",
    "    print(full_message)\n",
    "    log_dir = os.path.dirname(log_file)\n",
    "    if log_dir and not os.path.exists(log_dir): os.makedirs(log_dir)\n",
    "    try:\n",
    "        with open(log_file, 'a', encoding='utf-8') as f: f.write(full_message + '\\n')\n",
    "    except IOError as e: print(f\"Error writing k-mer log to {log_file}: {e}\")\n",
    "\n",
    "try:\n",
    "    with open(LOG_FILE_PATH_KMER, 'w', encoding='utf-8') as f: f.write(f\"--- K-mer Baseline Log Initialized: {datetime.datetime.now()} ---\\n\")\n",
    "    log_message_kmer(f\"K-mer Baseline Log started at: {LOG_FILE_PATH_KMER}\")\n",
    "except IOError as e: print(f\"CRITICAL ERROR: Could not write k-mer log {LOG_FILE_PATH_KMER}: {e}\")\n",
    "\n",
    "log_message_kmer(f\"Using device: {DEVICE} for k-mer operations.\")\n",
    "\n",
    "KMER_PAD_TOKEN = \"<PAD>\"\n",
    "KMER_UNK_TOKEN = \"<UNK>\"\n",
    "\n",
    "def sequence_to_kmers(sequence, k, stride=KMER_STRIDE):\n",
    "    kmers = []\n",
    "    if not isinstance(sequence, str) or len(sequence) < k: return [KMER_PAD_TOKEN]\n",
    "    for i in range(0, len(sequence) - k + 1, stride): kmers.append(sequence[i:i+k].upper())\n",
    "    if not kmers: kmers = [KMER_PAD_TOKEN]\n",
    "    return kmers\n",
    "\n",
    "def build_kmer_vocab(all_raw_sequences_list, k_values_list_for_vocab, kmer_stride_for_vocab, min_freq=1):\n",
    "    kmer_vocabs_map_build = {}\n",
    "    for k_val_build in k_values_list_for_vocab:\n",
    "        log_message_kmer(f\"Building vocabulary for k={k_val_build} using stride={kmer_stride_for_vocab}...\")\n",
    "        all_kmers_for_this_k_build = []\n",
    "        for seq_build in tqdm(all_raw_sequences_list, desc=f\"Tokenizing for k={k_val_build} vocab\"):\n",
    "            if not isinstance(seq_build, str): continue\n",
    "            all_kmers_for_this_k_build.extend(sequence_to_kmers(seq_build, k_val_build, stride=kmer_stride_for_vocab))\n",
    "        kmer_counts_build = pd.Series(all_kmers_for_this_k_build).value_counts()\n",
    "        frequent_kmers_build = kmer_counts_build[kmer_counts_build >= min_freq].index.tolist()\n",
    "        kmer_to_idx_build = {KMER_PAD_TOKEN: 0, KMER_UNK_TOKEN: 1}\n",
    "        for i_vocab, kmer_vocab_item in enumerate(frequent_kmers_build):\n",
    "            kmer_to_idx_build[kmer_vocab_item] = i_vocab + 2\n",
    "        idx_to_kmer_build = {idx: kmer for kmer, idx in kmer_to_idx_build.items()}\n",
    "        kmer_vocabs_map_build[k_val_build] = {\n",
    "            'kmer_to_idx': kmer_to_idx_build, 'idx_to_kmer': idx_to_kmer_build,\n",
    "            'vocab_size': len(kmer_to_idx_build),\n",
    "            'pad_idx': kmer_to_idx_build[KMER_PAD_TOKEN],\n",
    "            'unk_idx': kmer_to_idx_build[KMER_UNK_TOKEN]}\n",
    "        log_message_kmer(f\"Vocab for k={k_val_build} size: {len(kmer_to_idx_build)}.\")\n",
    "    return kmer_vocabs_map_build\n",
    "\n",
    "def kmer_numericalize_sequence(sequence_str, k_val_num, kmer_to_idx_map, max_kmer_seq_len_for_k, kmer_stride_for_num):\n",
    "    if not isinstance(sequence_str, str): sequence_str = \"\"\n",
    "    kmers_list = sequence_to_kmers(sequence_str, k_val_num, stride=kmer_stride_for_num)\n",
    "    pad_idx_local = kmer_to_idx_map[KMER_PAD_TOKEN]\n",
    "    unk_idx_local = kmer_to_idx_map[KMER_UNK_TOKEN]\n",
    "    numericalized = [kmer_to_idx_map.get(kmer, unk_idx_local) for kmer in kmers_list]\n",
    "    current_len = len(numericalized)\n",
    "    if current_len < max_kmer_seq_len_for_k:\n",
    "        numericalized.extend([pad_idx_local] * (max_kmer_seq_len_for_k - current_len))\n",
    "    elif current_len > max_kmer_seq_len_for_k:\n",
    "        numericalized = numericalized[:max_kmer_seq_len_for_k]\n",
    "    return np.array(numericalized, dtype=np.int64)\n",
    "\n",
    "def load_raw_sequences_for_kmer(file_path, is_promoter=True, seq_len_expected=SEQ_LEN_FOR_KMER_LOADING):\n",
    "    log_message_kmer(f\"Loading RAW sequences from {file_path} (expected len: {seq_len_expected})...\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        if not os.path.exists(file_path): raise FileNotFoundError(f\"Seq file missing: {file_path}\")\n",
    "        df = None; encodings_to_try = ['utf-8', 'ISO-8859-1', 'latin1']\n",
    "        for encoding in encodings_to_try:\n",
    "            try: df = pd.read_csv(file_path, encoding=encoding, low_memory=False); break\n",
    "            except: pass\n",
    "        if df is None: raise ValueError(f\"Could not read {file_path}\")\n",
    "        seq_col, id_col = None, None\n",
    "        possible_seq_cols=['promoter_sequence','sequence']; possible_id_cols=['gene_id', df.columns[0] if not df.empty else None]\n",
    "        for col_s in possible_seq_cols:\n",
    "            if col_s in df.columns: seq_col=col_s; break\n",
    "        for col_i in possible_id_cols:\n",
    "            if col_i in df.columns: id_col=col_i; break\n",
    "        if seq_col is None or id_col is None: raise ValueError(f\"Required cols not in {file_path}. Has: {df.columns.tolist()}\")\n",
    "        df[seq_col]=df[seq_col].astype(str); df=df[df[seq_col].str.strip()!='']\n",
    "        initial_raw_count = len(df) # Count before any QC for logging\n",
    "        df=df[~df[seq_col].str.contains('N',na=False,case=False)]; removed_n = initial_raw_count - len(df)\n",
    "        initial_count_after_N = len(df)\n",
    "        if seq_len_expected and seq_len_expected > 0:\n",
    "            df['seq_len_actual_temp'] = df[seq_col].str.len()\n",
    "            df_correct_len = df[df['seq_len_actual_temp'] == seq_len_expected]\n",
    "            removed_len = initial_count_after_N - len(df_correct_len)\n",
    "            df = df_correct_len.drop(columns=['seq_len_actual_temp'])\n",
    "            log_message_kmer(f\"QC {os.path.basename(file_path)}: Initial Raw={initial_raw_count}. After N-rem={initial_count_after_N}. Len-rem:{removed_len}. Final:{len(df)}.\")\n",
    "        else:\n",
    "            log_message_kmer(f\"QC {os.path.basename(file_path)}: Initial Raw={initial_raw_count}. After N-rem:{initial_count_after_N}. Len check skip. Final:{len(df)}.\")\n",
    "        if df.empty: log_message_kmer(f\"Warning: No valid raw sequences in {file_path}.\"); return [],[]\n",
    "        raw_sequences_list = df[seq_col].tolist(); labels_list = [1 if is_promoter else 0]*len(raw_sequences_list)\n",
    "        log_message_kmer(f\"Loaded {len(raw_sequences_list)} RAW sequences from {os.path.basename(file_path)} in {time.time()-start_time:.2f}s.\")\n",
    "        return raw_sequences_list, labels_list\n",
    "    except Exception as e: log_message_kmer(f\"CRITICAL ERROR loading RAW seq file {file_path}: {e}\"); raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83580da9-bd8d-43da-87bc-25e42237e8b9",
   "metadata": {},
   "source": [
    "## **3. K-mer Transformer Model Definition**\n",
    "Defines the `KmerTransformer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3349de5-8628-4a47-a672-05907dd8fe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 3. K-mer Transformer Model Definition\n",
    "# ============================================================================\n",
    "class KmerTransformer(nn.Module):\n",
    "    def __init__(self, kmer_vocab_size, max_kmer_seq_len,\n",
    "                 embed_dim=KMER_EMBED_DIM, num_heads=KMER_NUM_HEADS,\n",
    "                 ff_dim=KMER_TRANSFORMER_FF_DIM, num_layers=KMER_NUM_TRANSFORMER_LAYERS,\n",
    "                 dropout=KMER_DROPOUT_RATE, kmer_pad_idx=0): # Default kmer_pad_idx to 0 as per vocab\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(kmer_vocab_size, embed_dim, padding_idx=kmer_pad_idx)\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, max_kmer_seq_len, embed_dim))\n",
    "        self.embed_dropout = nn.Dropout(p=dropout)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_dim,\n",
    "            dropout=dropout, activation='relu', batch_first=True, norm_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Linear(embed_dim, embed_dim // 2), nn.ReLU(), nn.Dropout(p=dropout),\n",
    "            nn.Linear(embed_dim // 2, 1))\n",
    "\n",
    "    def forward(self, kmer_idx_sequence):\n",
    "        N, L_kmer_actual = kmer_idx_sequence.shape\n",
    "        x = self.embedding(kmer_idx_sequence) + self.positional_encoding[:, :L_kmer_actual, :]\n",
    "        x = self.embed_dropout(x)\n",
    "        padding_mask = (kmer_idx_sequence == self.embedding.padding_idx)\n",
    "        transformer_output = self.transformer_encoder(x, src_key_padding_mask=padding_mask)\n",
    "        mask = (~padding_mask).unsqueeze(-1).float()\n",
    "        aggregated_output = (transformer_output * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1.0)\n",
    "        return self.classifier(aggregated_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7555e2-f1bb-4daa-b800-1dda38469260",
   "metadata": {},
   "source": [
    "## **4. K-mer Dataset Definition**\n",
    "The `KmerDataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d27b36f-4b1a-49bd-a6bd-d419ada456f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 4. K-mer Dataset Definition\n",
    "# ============================================================================\n",
    "class KmerDataset(Dataset):\n",
    "    def __init__(self, list_of_raw_dna_strings, list_of_labels, k_value,\n",
    "                 kmer_vocabulary_dict, max_kmer_len_for_this_k, kmer_stride_val): # Pass stride\n",
    "        self.raw_sequences = list_of_raw_dna_strings\n",
    "        self.labels = torch.tensor(list_of_labels, dtype=torch.float32).unsqueeze(1)\n",
    "        self.k = k_value\n",
    "        self.kmer_to_idx = kmer_vocabulary_dict['kmer_to_idx']\n",
    "        self.max_kmer_seq_len = max_kmer_len_for_this_k\n",
    "        self.kmer_stride = kmer_stride_val # Store stride\n",
    "\n",
    "    def __len__(self): return len(self.raw_sequences)\n",
    "    def __getitem__(self, idx):\n",
    "        raw_seq_item = self.raw_sequences[idx]\n",
    "        if not isinstance(raw_seq_item, str): raw_seq_item = \"\"\n",
    "        kmer_indices_item = kmer_numericalize_sequence(\n",
    "            raw_seq_item, self.k, self.kmer_to_idx,\n",
    "            self.max_kmer_seq_len, kmer_stride_for_num=self.kmer_stride # Use stored stride\n",
    "        )\n",
    "        return {'kmer_indices': kmer_indices_item, 'label': self.labels[idx]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d66c080-bbf6-462e-a9ea-19ad7d328ce4",
   "metadata": {},
   "source": [
    "## **5. Training Function for Individual K-mer Models (with Checkpointing)**\n",
    "The `train_kmer_model` function with epoch-wise checkpointing and resuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77309a47-0e26-4b8e-b52a-6733b6d70809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 5. Training Function for Individual K-mer Models (with Checkpointing)\n",
    "# ============================================================================\n",
    "def train_kmer_model(k_value_train, kmer_model_instance, train_loader_k, val_loader_k,\n",
    "                     criterion_k, optimizer_k, num_epochs_k, device_k,\n",
    "                     model_best_save_path_tpl_k, loss_plot_path_tpl_k, scheduler_k=None,\n",
    "                     checkpoint_dir_tpl_k=KMER_CHECKPOINT_DIR_TPL):\n",
    "\n",
    "    k_checkpoint_dir = checkpoint_dir_tpl_k.format(k=k_value_train)\n",
    "    os.makedirs(k_checkpoint_dir, exist_ok=True)\n",
    "    k_model_best_save_path = model_best_save_path_tpl_k.format(k=k_value_train)\n",
    "    k_loss_plot_actual = loss_plot_path_tpl_k.format(k=k_value_train)\n",
    "\n",
    "    start_epoch = 0; train_losses_k, val_losses_k = [], []; best_val_loss_k = float('inf')\n",
    "\n",
    "    checkpoint_files = sorted(\n",
    "        glob.glob(os.path.join(k_checkpoint_dir, \"checkpoint_epoch_*.pth\")),\n",
    "        key=lambda x: int(re.search(r\"epoch_(\\d+)\\.pth\", os.path.basename(x)).group(1)) if re.search(r\"epoch_(\\d+)\\.pth\", os.path.basename(x)) else -1, # Robust key\n",
    "        reverse=True\n",
    "    )\n",
    "    if checkpoint_files:\n",
    "        latest_checkpoint_path = checkpoint_files[0]\n",
    "        log_message_kmer(f\"Resuming k={k_value_train} from checkpoint: {latest_checkpoint_path}\")\n",
    "        try:\n",
    "            checkpoint = torch.load(latest_checkpoint_path, map_location=device_k)\n",
    "            kmer_model_instance.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer_k.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            if scheduler_k and 'scheduler_state_dict' in checkpoint: scheduler_k.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "            start_epoch = checkpoint['epoch'] + 1\n",
    "            train_losses_k = checkpoint.get('train_losses', []); val_losses_k = checkpoint.get('val_losses', [])\n",
    "            best_val_loss_k = checkpoint.get('best_val_loss', float('inf'))\n",
    "            log_message_kmer(f\"Resumed from epoch {start_epoch-1}. Best Val Loss: {best_val_loss_k:.4f}\")\n",
    "        except Exception as e:\n",
    "            log_message_kmer(f\"Error loading checkpoint {latest_checkpoint_path}: {e}. Training k={k_value_train} from scratch.\")\n",
    "            start_epoch = 0; train_losses_k, val_losses_k = [], []; best_val_loss_k = float('inf')\n",
    "    \n",
    "    if start_epoch >= num_epochs_k:\n",
    "        log_message_kmer(f\"k={k_value_train} already trained for {num_epochs_k} epochs. Skipping.\")\n",
    "        if os.path.exists(k_model_best_save_path):\n",
    "            try: kmer_model_instance.load_state_dict(torch.load(k_model_best_save_path, map_location=device_k))\n",
    "            except: log_message_kmer(f\"Could not load best model for k={k_value_train}.\")\n",
    "        return kmer_model_instance\n",
    "\n",
    "    log_message_kmer(f\"--- Training KmerTransformer (k={k_value_train}) from epoch {start_epoch} to {num_epochs_k-1} ---\")\n",
    "    for epoch_k in range(start_epoch, num_epochs_k):\n",
    "        epoch_start_time = time.time(); kmer_model_instance.train(); running_train_loss_k = 0.0\n",
    "        train_loop_k = tqdm(train_loader_k, desc=f\"k={k_value_train} E{epoch_k+1}/{num_epochs_k} [Train]\", leave=False)\n",
    "        for batch_k in train_loop_k:\n",
    "            kmer_indices_k=batch_k['kmer_indices'].to(device_k); labels_k=batch_k['label'].to(device_k)\n",
    "            optimizer_k.zero_grad(); logits_k=kmer_model_instance(kmer_indices_k); loss_k=criterion_k(logits_k,labels_k)\n",
    "            loss_k.backward(); optimizer_k.step(); running_train_loss_k += loss_k.item()\n",
    "            train_loop_k.set_postfix(loss=f\"{loss_k.item():.4f}\")\n",
    "        epoch_train_loss_k = running_train_loss_k/len(train_loader_k) if len(train_loader_k)>0 else 0.0\n",
    "        train_losses_k.append(epoch_train_loss_k)\n",
    "\n",
    "        kmer_model_instance.eval(); running_val_loss_k = 0.0\n",
    "        val_loop_k = tqdm(val_loader_k, desc=f\"k={k_value_train} E{epoch_k+1}/{num_epochs_k} [Val]\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for batch_k_val in val_loop_k:\n",
    "                kmer_indices_k_val=batch_k_val['kmer_indices'].to(device_k); labels_k_val=batch_k_val['label'].to(device_k)\n",
    "                logits_k_val=kmer_model_instance(kmer_indices_k_val); loss_k_val=criterion_k(logits_k_val,labels_k_val)\n",
    "                running_val_loss_k += loss_k_val.item(); val_loop_k.set_postfix(loss=f\"{loss_k_val.item():.4f}\")\n",
    "        epoch_val_loss_k = running_val_loss_k/len(val_loader_k) if len(val_loader_k)>0 else 0.0\n",
    "        val_losses_k.append(epoch_val_loss_k)\n",
    "        current_lr_k = optimizer_k.param_groups[0]['lr']\n",
    "        if scheduler_k: scheduler_k.step(epoch_val_loss_k)\n",
    "        log_message_kmer(f\"k={k_value_train} E {epoch_k+1}/{num_epochs_k} - TrL: {epoch_train_loss_k:.4f}, VaL: {epoch_val_loss_k:.4f}, Dur: {time.time()-epoch_start_time:.2f}s, LR: {current_lr_k:.2e}\")\n",
    "        \n",
    "        if epoch_val_loss_k < best_val_loss_k:\n",
    "            best_val_loss_k = epoch_val_loss_k; torch.save(kmer_model_instance.state_dict(), k_model_best_save_path)\n",
    "            log_message_kmer(f\"k={k_value_train} Saved NEW BEST model (Val Loss: {best_val_loss_k:.4f}) to {k_model_best_save_path}\")\n",
    "        \n",
    "        checkpoint_save_path = os.path.join(k_checkpoint_dir, f\"checkpoint_epoch_{epoch_k:03d}.pth\")\n",
    "        checkpoint_data_save = {'epoch': epoch_k, 'model_state_dict': kmer_model_instance.state_dict(),\n",
    "                                'optimizer_state_dict': optimizer_k.state_dict(), 'train_losses': train_losses_k,\n",
    "                                'val_losses': val_losses_k, 'best_val_loss': best_val_loss_k}\n",
    "        if scheduler_k: checkpoint_data_save['scheduler_state_dict'] = scheduler_k.state_dict()\n",
    "        torch.save(checkpoint_data_save, checkpoint_save_path)\n",
    "\n",
    "    if train_losses_k and val_losses_k and len(train_losses_k) > 0:\n",
    "        try:\n",
    "            epochs_plotted = len(train_losses_k); epochs_range_k = range(1, epochs_plotted + 1)\n",
    "            plt.figure(figsize=(10,6)); plt.plot(epochs_range_k,train_losses_k,label=f'k={k_value_train} Train',marker='.'); plt.plot(epochs_range_k,val_losses_k,label=f'k={k_value_train} Val',marker='.')\n",
    "            plt.xlabel('Epochs'); plt.ylabel('Loss'); plt.title(f'k={k_value_train} Train/Val Loss (Up to Epoch {epochs_plotted})'); plt.legend(); plt.grid(True,linestyle=':'); plt.tight_layout(); plt.savefig(k_loss_plot_actual, dpi=300); plt.close()\n",
    "            log_message_kmer(f\"k={k_value_train} Saved final loss plot to {k_loss_plot_actual}\")\n",
    "        except Exception as e: log_message_kmer(f\"Error plotting k={k_value_train} loss: {e}\")\n",
    "    \n",
    "    log_message_kmer(f\"--- k={k_value_train} Training Finished/Resumed --- Best Val Loss: {best_val_loss_k:.4f}\")\n",
    "    if os.path.exists(k_model_best_save_path):\n",
    "        try: kmer_model_instance.load_state_dict(torch.load(k_model_best_save_path, map_location=device_k))\n",
    "        except: log_message_kmer(f\"k={k_value_train} Error loading BEST model for return.\")\n",
    "    return kmer_model_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fb338f-c326-4fa0-9081-78b0a6716cc8",
   "metadata": {},
   "source": [
    "## **6. Ensemble Evaluation Function**\n",
    "The `evaluate_kmer_ensemble` function combines predictions. Helper `RawSequenceDatasetForEnsemble`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab99dff7-7c75-4d25-8344-e5f6a84c9c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 6. Ensemble Evaluation Function\n",
    "# ============================================================================\n",
    "class RawSequenceDatasetForEnsemble(Dataset):\n",
    "    def __init__(self, list_of_raw_dna_strings, list_of_labels):\n",
    "        self.raw_seqs = list_of_raw_dna_strings\n",
    "        self.labels = torch.tensor(list_of_labels, dtype=torch.float32)\n",
    "        if self.labels.ndim == 1: self.labels = self.labels.unsqueeze(1)\n",
    "    def __len__(self): return len(self.raw_seqs)\n",
    "    def __getitem__(self, idx):\n",
    "        return {'raw_sequence_list': [self.raw_seqs[idx]], 'label_list': self.labels[idx]}\n",
    "\n",
    "def plot_confusion_matrix_kmer(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues, save_path=\"cm.png\"):\n",
    "    try:\n",
    "        if normalize:\n",
    "            cm_sum = cm.sum(axis=1)[:, np.newaxis]\n",
    "            cm_plot = np.divide(cm.astype('float'), cm_sum, out=np.zeros_like(cm,dtype=float), where=cm_sum!=0)\n",
    "            fmt = '.2f'; plot_title = title + ' (Normalized)'\n",
    "        else: fmt = 'd'; cm_plot = cm; plot_title = title\n",
    "        plt.figure(figsize=(8,6)); sns.heatmap(cm_plot, annot=True, fmt=fmt, cmap=cmap, xticklabels=classes, yticklabels=classes, square=True, cbar=False, linewidths=.5, linecolor='grey', annot_kws={\"size\":10}); plt.title(plot_title, fontsize=14); plt.ylabel('True label', fontsize=12); plt.xlabel('Predicted label', fontsize=12); plt.xticks(fontsize=10); plt.yticks(fontsize=10,rotation=0); plt.tight_layout(); plt.savefig(save_path, dpi=300); plt.close()\n",
    "        log_message_kmer(f\"Saved CM to {save_path}\")\n",
    "    except Exception as e: log_message_kmer(f\"Error plotting CM: {e}\")\n",
    "\n",
    "def evaluate_kmer_ensemble(dict_of_trained_k_models, test_raw_seq_loader, k_val_list,\n",
    "                           kmer_vocab_map_eval, max_kmer_len_map_eval, device_eval,\n",
    "                           kmer_stride_for_eval,\n",
    "                           results_csv_path_ens=ENSEMBLE_RESULTS_CSV_PATH,\n",
    "                           cm_plot_path_base_ens=ENSEMBLE_CM_PLOT_PATH_BASE):\n",
    "    log_message_kmer(f\"--- Evaluating K-mer Ensemble on Test Set ---\")\n",
    "    all_ensemble_labels, all_ensembled_probabilities = [], []\n",
    "    for model_k in dict_of_trained_k_models.values():\n",
    "        if model_k: model_k.eval()\n",
    "    with torch.no_grad():\n",
    "        test_raw_loop = tqdm(test_raw_seq_loader, desc=\"Ensemble Test Evaluation\", leave=False)\n",
    "        for batch_raw in test_raw_loop:\n",
    "            raw_sequences_in_batch_outer = batch_raw['raw_sequence_list']\n",
    "            raw_sequences_in_batch_flat = [item for sublist in raw_sequences_in_batch_outer for item in sublist]\n",
    "            labels_in_batch = batch_raw['label_list']\n",
    "            batch_all_k_probs_list = []\n",
    "            for k_val_ens in k_val_list:\n",
    "                model_instance_ens = dict_of_trained_k_models.get(k_val_ens)\n",
    "                if model_instance_ens:\n",
    "                    kmer_indices_for_batch_k = np.array([kmer_numericalize_sequence(\n",
    "                        s, k_val_ens, kmer_vocab_map_eval[k_val_ens]['kmer_to_idx'],\n",
    "                        max_kmer_len_map_eval[k_val_ens], kmer_stride_for_num=kmer_stride_for_eval\n",
    "                    ) for s in raw_sequences_in_batch_flat])\n",
    "                    kmer_indices_tensor_k = torch.tensor(kmer_indices_for_batch_k).to(device_eval)\n",
    "                    logits_k_ens = model_instance_ens(kmer_indices_tensor_k); probs_k_ens = torch.sigmoid(logits_k_ens)\n",
    "                    batch_all_k_probs_list.append(probs_k_ens)\n",
    "                else: batch_all_k_probs_list.append(torch.full((len(raw_sequences_in_batch_flat),1),0.5,device=device_eval))\n",
    "            if batch_all_k_probs_list:\n",
    "                avg_probs_for_batch = torch.mean(torch.stack(batch_all_k_probs_list, dim=0), dim=0)\n",
    "                all_ensembled_probabilities.extend(avg_probs_for_batch.cpu().numpy())\n",
    "                all_ensemble_labels.extend(labels_in_batch.cpu().numpy() if isinstance(labels_in_batch,torch.Tensor) else labels_in_batch)\n",
    "            else:\n",
    "                all_ensemble_labels.extend(labels_in_batch.cpu().numpy() if isinstance(labels_in_batch,torch.Tensor) else labels_in_batch)\n",
    "                all_ensembled_probabilities.extend(np.full((len(labels_in_batch),1),0.5))\n",
    "    if not all_ensemble_labels: log_message_kmer(\"No predictions for ensemble.\"); return {}\n",
    "    all_labels_np=np.array(all_ensemble_labels).flatten(); all_probs_np=np.array(all_ensembled_probabilities).flatten(); all_preds_np=(all_probs_np > 0.5).astype(float)\n",
    "    acc=accuracy_score(all_labels_np,all_preds_np); prec=precision_score(all_labels_np,all_preds_np,zero_division=0)\n",
    "    rec=recall_score(all_labels_np,all_preds_np,zero_division=0); f1=f1_score(all_labels_np,all_preds_np,zero_division=0)\n",
    "    unique_lbls=np.unique(all_labels_np); cm_lbls=[0,1] if len(unique_lbls)==2 else unique_lbls.tolist() if len(unique_lbls)==1 else [0,1]\n",
    "    if not cm_lbls: cm_lbls=[0,1]\n",
    "    cm=confusion_matrix(all_labels_np,all_preds_np,labels=cm_lbls)\n",
    "    if cm.shape==(2,2): tn,fp,fn,tp=cm.ravel()\n",
    "    elif cm.shape==(1,1) and 0 in cm_lbls: tn,fp,fn,tp=cm[0,0],0,0,0\n",
    "    elif cm.shape==(1,1) and 1 in cm_lbls: tn,fp,fn,tp=0,0,0,cm[0,0]\n",
    "    else: log_message_kmer(f\"Ens CM unhandled: {cm.shape},{cm_lbls}.\"); tn,fp,fn,tp=0,0,0,0\n",
    "    spec=tn/(tn+fp) if (tn+fp)>0 else 0.0\n",
    "    auc=roc_auc_score(all_labels_np,all_probs_np) if len(unique_lbls)>1 else np.nan\n",
    "    if np.isnan(auc):log_message_kmer(\"Ens AUC is NaN.\")\n",
    "    results={'model':'msBERT_rep_ensemble','acc':acc,'prec':prec,'rec':rec,'spec':spec,'f1':f1,'auc':auc,'TP':int(tp),'FP':int(fp),'TN':int(tn),'FN':int(fn)}\n",
    "    log_message_kmer(\"\\n--- K-mer Ensemble Test Results ---\")\n",
    "    for k,v in results.items(): log_message_kmer(f\"{k.upper()}: {v:.4f}\" if isinstance(v,float) else f\"{k.upper()}: {v}\")\n",
    "    plot_confusion_matrix_kmer(cm,['Non-P','P'],title='K-mer Ens Test CM (Counts)',save_path=cm_plot_path_base_ens+\"_counts.png\")\n",
    "    plot_confusion_matrix_kmer(cm,['Non-P','P'],normalize=True,title='K-mer Ens Test CM (Norm)',save_path=cm_plot_path_base_ens+\"_norm.png\")\n",
    "    pd.DataFrame([results]).to_csv(results_csv_path_ens,index=False); log_message_kmer(f\"Saved K-mer Ens test results to {results_csv_path_ens}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f079b307-cda8-4288-a652-f5594c4bf408",
   "metadata": {},
   "source": [
    "## **7. Main Execution Block for msBERT-Promoter Replication**\n",
    "This block orchestrates the replication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "058b7923-77ef-44a6-8600-136e2cb0d14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-19 13:18:59] --- Starting msBERT-Promoter Replication Workflow (PID: 3459) ---\n",
      "[2025-06-19 13:18:59] K-mer Baseline Config: Epochs=10, Batch=32, LR=0.0001, ForceRebuild=False\n",
      "[2025-06-19 13:18:59] \n",
      "--- Step 1: Loading Raw Sequence Data ---\n",
      "[2025-06-19 13:18:59] Loading RAW sequences from ./data/raw/human_genome_annotation/updated_promoter_features_clean.csv (expected len: 2000)...\n",
      "[2025-06-19 13:19:00] QC updated_promoter_features_clean.csv: Initial Raw=20028. After N-rem=20028. Len-rem:0. Final:20028.\n",
      "[2025-06-19 13:19:00] Loaded 20028 RAW sequences from updated_promoter_features_clean.csv in 0.71s.\n",
      "[2025-06-19 13:19:00] Loading RAW sequences from ./data/raw/human_genome_annotation/updated_non_promoter_sequences.csv (expected len: 2000)...\n",
      "[2025-06-19 13:19:01] QC updated_non_promoter_sequences.csv: Initial Raw=20028. After N-rem=20028. Len-rem:0. Final:20028.\n",
      "[2025-06-19 13:19:01] Loaded 20028 RAW sequences from updated_non_promoter_sequences.csv in 0.64s.\n",
      "[2025-06-19 13:19:01] Total raw sequences for k-mer models: 40056\n",
      "[2025-06-19 13:19:01] \n",
      "--- Step 2: Building K-mer Vocabularies ---\n",
      "[2025-06-19 13:19:01] Building vocabulary for k=3 using stride=1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49fa5dbbd188460b930b271bd4c36736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing for k=3 vocab:   0%|          | 0/40056 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-19 13:19:25] Vocab for k=3 size: 66.\n",
      "[2025-06-19 13:19:25] Building vocabulary for k=4 using stride=1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e82c54c04f44b65b8da9359893077ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing for k=4 vocab:   0%|          | 0/40056 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-19 13:19:49] Vocab for k=4 size: 258.\n",
      "[2025-06-19 13:19:49] Building vocabulary for k=5 using stride=1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ace61cb5cfb4436b23defa7096abdf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing for k=5 vocab:   0%|          | 0/40056 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-19 13:20:15] Vocab for k=5 size: 1026.\n",
      "[2025-06-19 13:20:15] Building vocabulary for k=6 using stride=1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a3bbf2f8bb400180e9170ef18cb291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing for k=6 vocab:   0%|          | 0/40056 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-19 13:20:42] Vocab for k=6 size: 4098.\n",
      "[2025-06-19 13:20:43] \n",
      "--- Step 3: Calculating Max K-mer Sequence Lengths ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bacb64b804154f608d0252a542d8e483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Max k-mer len for k=3:   0%|          | 0/40056 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-19 13:20:57] Max k-mer seq length for k=3: 1998\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38da88a1b02a4bb8ad47a9c7c5a6fb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Max k-mer len for k=4:   0%|          | 0/40056 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-19 13:21:11] Max k-mer seq length for k=4: 1997\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50adff1ed55d4a0d9ce623862c6a6d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Max k-mer len for k=5:   0%|          | 0/40056 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-19 13:21:25] Max k-mer seq length for k=5: 1996\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f99e0bdd734ed58d6e7378c26ee3a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Max k-mer len for k=6:   0%|          | 0/40056 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-19 13:21:40] Max k-mer seq length for k=6: 1995\n",
      "[2025-06-19 13:21:40] \n",
      "--- Step 4: Training/Loading Individual K-mer Models ---\n",
      "[2025-06-19 13:21:40] K-mer Data Split: Train=28040, Val=6008, Test=6008\n",
      "[2025-06-19 13:21:40] \n",
      "--- Processing for k=3 ---\n",
      "[2025-06-19 13:21:41] Resuming k=3 from checkpoint: results_msBERT_replication/checkpoints_k3/checkpoint_epoch_003.pth\n",
      "[2025-06-19 13:21:41] Resumed from epoch 3. Best Val Loss: 0.4831\n",
      "[2025-06-19 13:21:41] --- Training KmerTransformer (k=3) from epoch 4 to 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fe0c2a59794e689b596b75f6fcc052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=3 E5/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffde4e69e9b4422aa0061a374137930b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=3 E5/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-19 20:22:21] k=3 E 5/10 - TrL: 0.4937, VaL: 0.4784, Dur: 25240.26s, LR: 1.00e-04\n",
      "[2025-06-19 20:22:21] k=3 Saved NEW BEST model (Val Loss: 0.4784) to results_msBERT_replication/best_kmer_model_k3.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7e914585014b1b884379cfb7b0f49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=3 E6/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6277af7cfa4cecaa1c7e1dba1a80b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=3 E6/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-20 03:07:35] k=3 E 6/10 - TrL: 0.4910, VaL: 0.4741, Dur: 24314.11s, LR: 1.00e-04\n",
      "[2025-06-20 03:07:35] k=3 Saved NEW BEST model (Val Loss: 0.4741) to results_msBERT_replication/best_kmer_model_k3.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bce5eae9363418b8b7cf21315f6eba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=3 E7/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e872767a3b4f8792f8d0547fe83b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=3 E7/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-20 10:02:59] k=3 E 7/10 - TrL: 0.4883, VaL: 0.5122, Dur: 24923.51s, LR: 1.00e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8444933c1369433eac3941b2cafccb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=3 E8/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77b466165fa4bfe91c62cf700a8d559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=3 E8/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-20 16:52:46] k=3 E 8/10 - TrL: 0.4839, VaL: 0.4696, Dur: 24587.20s, LR: 1.00e-04\n",
      "[2025-06-20 16:52:46] k=3 Saved NEW BEST model (Val Loss: 0.4696) to results_msBERT_replication/best_kmer_model_k3.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2330a6d465f4446190fe9a415701dab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=3 E9/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe70c7e727f4b3986cae0d1affb3383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=3 E9/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-20 23:49:10] k=3 E 9/10 - TrL: 0.4822, VaL: 0.4851, Dur: 24984.03s, LR: 1.00e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6029afa955423892f35ddea8163dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=3 E10/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab5a62cd69541f2849aeccd8ccb5855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=3 E10/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-21 06:36:15] k=3 E 10/10 - TrL: 0.4783, VaL: 0.4966, Dur: 24425.07s, LR: 1.00e-04\n",
      "[2025-06-21 06:36:17] k=3 Saved final loss plot to results_msBERT_replication/loss_kmer_k3.png\n",
      "[2025-06-21 06:36:17] --- k=3 Training Finished/Resumed --- Best Val Loss: 0.4696\n",
      "[2025-06-21 06:36:17] \n",
      "--- Processing for k=4 ---\n",
      "[2025-06-21 06:36:17] --- Training KmerTransformer (k=4) from epoch 0 to 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ba431ad9e343feaa6479bb3760e9e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E1/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ef29e54462453e82e01696a67f817c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E1/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-21 13:22:39] k=4 E 1/10 - TrL: 0.6056, VaL: 0.5360, Dur: 24382.13s, LR: 1.00e-04\n",
      "[2025-06-21 13:22:39] k=4 Saved NEW BEST model (Val Loss: 0.5360) to results_msBERT_replication/best_kmer_model_k4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9fab60ac554405692d1517197a62276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E2/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d637f2090654ec6a603e6fc7262b186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E2/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-21 20:03:34] k=4 E 2/10 - TrL: 0.5302, VaL: 0.5077, Dur: 24054.65s, LR: 1.00e-04\n",
      "[2025-06-21 20:03:34] k=4 Saved NEW BEST model (Val Loss: 0.5077) to results_msBERT_replication/best_kmer_model_k4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b999328ed9804a25a59330dd84e3b5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E3/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58db5fdf19045b7932cbe0da4bd40f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E3/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-22 02:44:17] k=4 E 3/10 - TrL: 0.5145, VaL: 0.5036, Dur: 24042.68s, LR: 1.00e-04\n",
      "[2025-06-22 02:44:17] k=4 Saved NEW BEST model (Val Loss: 0.5036) to results_msBERT_replication/best_kmer_model_k4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c62399900134f2487c4f5fcb347ea68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E4/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063134fa81dc47b5aee150d7dfe78afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E4/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-22 09:24:16] k=4 E 4/10 - TrL: 0.5038, VaL: 0.4891, Dur: 23999.41s, LR: 1.00e-04\n",
      "[2025-06-22 09:24:16] k=4 Saved NEW BEST model (Val Loss: 0.4891) to results_msBERT_replication/best_kmer_model_k4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9da69b6ecd46c2b838396d7bdccbbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E5/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49c4ac11de04d969da5386c4ee04638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E5/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-22 17:49:20] k=4 E 5/10 - TrL: 0.4999, VaL: 0.4927, Dur: 30304.26s, LR: 1.00e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00143a03b02946878e86929ca1f2eb1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E6/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde6bfed634b4f8a93cffe8b59f3673f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E6/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-23 02:19:40] k=4 E 6/10 - TrL: 0.4960, VaL: 0.4901, Dur: 30619.89s, LR: 1.00e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50310e8373844685898aba49b15f228b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E7/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d91d937feb649a4b03f631362489a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E7/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-23 09:00:34] k=4 E 7/10 - TrL: 0.4902, VaL: 0.4816, Dur: 24054.04s, LR: 1.00e-04\n",
      "[2025-06-23 09:00:34] k=4 Saved NEW BEST model (Val Loss: 0.4816) to results_msBERT_replication/best_kmer_model_k4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0270c552aa4154a7e74670c8490856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E8/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61dc6ba031a8444ea2439887d82f487a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E8/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-23 17:19:59] k=4 E 8/10 - TrL: 0.4871, VaL: 0.4769, Dur: 29964.41s, LR: 1.00e-04\n",
      "[2025-06-23 17:19:59] k=4 Saved NEW BEST model (Val Loss: 0.4769) to results_msBERT_replication/best_kmer_model_k4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d7ef975d844de5b94db211e2f2b9df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E9/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd63bb0cd704483086f2e4afc055bbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E9/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-23 23:58:56] k=4 E 9/10 - TrL: 0.4862, VaL: 0.4794, Dur: 23937.15s, LR: 1.00e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c386a7d8e44c799af2a7c2d510af7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E10/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d22c314e4a4b85ab36e1b6774d8d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=4 E10/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-24 06:38:23] k=4 E 10/10 - TrL: 0.4825, VaL: 0.4789, Dur: 23966.86s, LR: 1.00e-04\n",
      "[2025-06-24 06:38:24] k=4 Saved final loss plot to results_msBERT_replication/loss_kmer_k4.png\n",
      "[2025-06-24 06:38:24] --- k=4 Training Finished/Resumed --- Best Val Loss: 0.4769\n",
      "[2025-06-24 06:38:24] \n",
      "--- Processing for k=5 ---\n",
      "[2025-06-24 06:38:24] --- Training KmerTransformer (k=5) from epoch 0 to 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c2c907c6d24f84830cef7c229cb4e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E1/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c659f4adf640178a8fec90dd377f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E1/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-24 14:26:04] k=5 E 1/10 - TrL: 0.6119, VaL: 0.5528, Dur: 28059.74s, LR: 1.00e-04\n",
      "[2025-06-24 14:26:04] k=5 Saved NEW BEST model (Val Loss: 0.5528) to results_msBERT_replication/best_kmer_model_k5.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417c8660326b41078a02e25732358763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E2/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a7b3ee850d4d3a93f1f3ca8c34e4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E2/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-24 21:14:21] k=5 E 2/10 - TrL: 0.5393, VaL: 0.5277, Dur: 24496.94s, LR: 1.00e-04\n",
      "[2025-06-24 21:14:21] k=5 Saved NEW BEST model (Val Loss: 0.5277) to results_msBERT_replication/best_kmer_model_k5.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fe247b62da46b5949c94ba2a3cd437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E3/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc449501214b4ae28cf04e177befe886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E3/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-25 03:58:51] k=5 E 3/10 - TrL: 0.5250, VaL: 0.5122, Dur: 24269.64s, LR: 1.00e-04\n",
      "[2025-06-25 03:58:51] k=5 Saved NEW BEST model (Val Loss: 0.5122) to results_msBERT_replication/best_kmer_model_k5.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0962d53eb8f948cf81c9304fb0ff57c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E4/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0ae76094ae47b6b3d88e9df9c68143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E4/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-25 10:43:38] k=5 E 4/10 - TrL: 0.5135, VaL: 0.5142, Dur: 24287.68s, LR: 1.00e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca9427ecf6f447597378225de416391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E5/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5c352fcb2b4686ab1cbf9fc5fc7e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E5/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-25 17:39:01] k=5 E 5/10 - TrL: 0.5062, VaL: 0.4964, Dur: 24923.06s, LR: 1.00e-04\n",
      "[2025-06-25 17:39:01] k=5 Saved NEW BEST model (Val Loss: 0.4964) to results_msBERT_replication/best_kmer_model_k5.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758b5b82b76e41379658d7355081fce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E6/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d842cfdcb3a4520aed90775b42998cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E6/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-26 00:24:19] k=5 E 6/10 - TrL: 0.4974, VaL: 0.4877, Dur: 24317.79s, LR: 1.00e-04\n",
      "[2025-06-26 00:24:19] k=5 Saved NEW BEST model (Val Loss: 0.4877) to results_msBERT_replication/best_kmer_model_k5.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543d234c158c4123917eaa10e07fcf8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E7/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61d9214b4024efb8bf78b9c4516900b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E7/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-26 07:08:51] k=5 E 7/10 - TrL: 0.4911, VaL: 0.4837, Dur: 24271.84s, LR: 1.00e-04\n",
      "[2025-06-26 07:08:51] k=5 Saved NEW BEST model (Val Loss: 0.4837) to results_msBERT_replication/best_kmer_model_k5.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d82dc7fce864655bb0ecb86db5b70af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E8/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96df4d0b0dca4b848455333ba1041a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E8/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-26 14:07:06] k=5 E 8/10 - TrL: 0.4876, VaL: 0.4793, Dur: 25094.23s, LR: 1.00e-04\n",
      "[2025-06-26 14:07:06] k=5 Saved NEW BEST model (Val Loss: 0.4793) to results_msBERT_replication/best_kmer_model_k5.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371e52f92bfa4eed9446ea91419fbbe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E9/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec769ef97e24afca02f910462552f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E9/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-26 20:57:01] k=5 E 9/10 - TrL: 0.4818, VaL: 0.4720, Dur: 24595.19s, LR: 1.00e-04\n",
      "[2025-06-26 20:57:01] k=5 Saved NEW BEST model (Val Loss: 0.4720) to results_msBERT_replication/best_kmer_model_k5.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38dbcdb94e0a48d1a4356abbb645fa2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E10/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2a7f9daeae49898d7d2aa61642dc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=5 E10/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-27 03:42:53] k=5 E 10/10 - TrL: 0.4768, VaL: 0.4717, Dur: 24352.57s, LR: 1.00e-04\n",
      "[2025-06-27 03:42:54] k=5 Saved NEW BEST model (Val Loss: 0.4717) to results_msBERT_replication/best_kmer_model_k5.pth\n",
      "[2025-06-27 03:42:54] k=5 Saved final loss plot to results_msBERT_replication/loss_kmer_k5.png\n",
      "[2025-06-27 03:42:54] --- k=5 Training Finished/Resumed --- Best Val Loss: 0.4717\n",
      "[2025-06-27 03:42:54] \n",
      "--- Processing for k=6 ---\n",
      "[2025-06-27 03:42:54] --- Training KmerTransformer (k=6) from epoch 0 to 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41ec289c488427090c542481df896d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E1/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a2b1cd31bf4e448f86642d688d4575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E1/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-27 10:22:06] k=6 E 1/10 - TrL: 0.6420, VaL: 0.5701, Dur: 23951.45s, LR: 1.00e-04\n",
      "[2025-06-27 10:22:06] k=6 Saved NEW BEST model (Val Loss: 0.5701) to results_msBERT_replication/best_kmer_model_k6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fdae8ac20a421e8029e6897fb9b6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E2/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c038651afe74bf7812cbdcdc090d835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E2/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-27 17:45:24] k=6 E 2/10 - TrL: 0.5609, VaL: 0.5480, Dur: 26597.69s, LR: 1.00e-04\n",
      "[2025-06-27 17:45:24] k=6 Saved NEW BEST model (Val Loss: 0.5480) to results_msBERT_replication/best_kmer_model_k6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0a717585ac4bacb7def4a37c1259bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E3/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53c5b3b8fdb45d6b03ba5d274c51cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E3/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-28 00:26:34] k=6 E 3/10 - TrL: 0.5364, VaL: 0.5340, Dur: 24070.20s, LR: 1.00e-04\n",
      "[2025-06-28 00:26:34] k=6 Saved NEW BEST model (Val Loss: 0.5340) to results_msBERT_replication/best_kmer_model_k6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f064848bc7142609d55c994565b450d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E4/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f148b8a0bb2d4596818dc5ecf20c8ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E4/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-28 07:07:03] k=6 E 4/10 - TrL: 0.5237, VaL: 0.5161, Dur: 24028.94s, LR: 1.00e-04\n",
      "[2025-06-28 07:07:03] k=6 Saved NEW BEST model (Val Loss: 0.5161) to results_msBERT_replication/best_kmer_model_k6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140a74e797194bbc96b27f9734cd2841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E5/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686e9b2bdbd04eda9c3efe79406c707c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E5/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-28 13:52:28] k=6 E 5/10 - TrL: 0.5145, VaL: 0.5101, Dur: 24325.46s, LR: 1.00e-04\n",
      "[2025-06-28 13:52:29] k=6 Saved NEW BEST model (Val Loss: 0.5101) to results_msBERT_replication/best_kmer_model_k6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb9f43d93f64a6f882b0a704e60893f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E6/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c44249cbde4cef811a459cf4cdb1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E6/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-28 21:11:48] k=6 E 6/10 - TrL: 0.5072, VaL: 0.5040, Dur: 26359.60s, LR: 1.00e-04\n",
      "[2025-06-28 21:11:48] k=6 Saved NEW BEST model (Val Loss: 0.5040) to results_msBERT_replication/best_kmer_model_k6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7960d2da113f4a5a903350d587a9de74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E7/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f93b4eda8144f55a2ef5d6c1f46bf41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E7/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-29 03:52:56] k=6 E 7/10 - TrL: 0.4982, VaL: 0.4979, Dur: 24068.22s, LR: 1.00e-04\n",
      "[2025-06-29 03:52:57] k=6 Saved NEW BEST model (Val Loss: 0.4979) to results_msBERT_replication/best_kmer_model_k6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbd808fe5174e0c8d4111911335da33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E8/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e60ec2f2cc24f33911aa3ff9c93d507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E8/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-29 10:34:03] k=6 E 8/10 - TrL: 0.4904, VaL: 0.4895, Dur: 24066.74s, LR: 1.00e-04\n",
      "[2025-06-29 10:34:03] k=6 Saved NEW BEST model (Val Loss: 0.4895) to results_msBERT_replication/best_kmer_model_k6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3450023f63254b19915f96400eb08eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E9/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038de09d7cde47b9b902fb6a106b9e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E9/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-29 18:21:26] k=6 E 9/10 - TrL: 0.4822, VaL: 0.4897, Dur: 28042.61s, LR: 1.00e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88704248d594a808113d6b6e7757e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E10/10 [Train]:   0%|          | 0/877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af23026660c14deb94bdab7b6842f7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "k=6 E10/10 [Val]:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-30 01:02:17] k=6 E 10/10 - TrL: 0.4773, VaL: 0.4818, Dur: 24051.29s, LR: 1.00e-04\n",
      "[2025-06-30 01:02:17] k=6 Saved NEW BEST model (Val Loss: 0.4818) to results_msBERT_replication/best_kmer_model_k6.pth\n",
      "[2025-06-30 01:02:18] k=6 Saved final loss plot to results_msBERT_replication/loss_kmer_k6.png\n",
      "[2025-06-30 01:02:18] --- k=6 Training Finished/Resumed --- Best Val Loss: 0.4818\n",
      "[2025-06-30 01:02:18] \n",
      "--- Step 5: Evaluating K-mer Ensemble ---\n",
      "[2025-06-30 01:02:19] --- Evaluating K-mer Ensemble on Test Set ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b9c91fe443472eb9c1e4285da2eb55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ensemble Test Evaluation:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-30 02:33:03] \n",
      "--- K-mer Ensemble Test Results ---\n",
      "[2025-06-30 02:33:03] MODEL: msBERT_rep_ensemble\n",
      "[2025-06-30 02:33:03] ACC: 0.7833\n",
      "[2025-06-30 02:33:03] PREC: 0.8796\n",
      "[2025-06-30 02:33:03] REC: 0.6587\n",
      "[2025-06-30 02:33:03] SPEC: 0.9090\n",
      "[2025-06-30 02:33:03] F1: 0.7533\n",
      "[2025-06-30 02:33:03] AUC: 0.8539\n",
      "[2025-06-30 02:33:03] TP: 1988\n",
      "[2025-06-30 02:33:03] FP: 272\n",
      "[2025-06-30 02:33:03] TN: 2718\n",
      "[2025-06-30 02:33:03] FN: 1030\n",
      "[2025-06-30 02:33:04] Saved CM to results_msBERT_replication/confusion_matrix_kmer_ensemble_counts.png\n",
      "[2025-06-30 02:33:04] Saved CM to results_msBERT_replication/confusion_matrix_kmer_ensemble_norm.png\n",
      "[2025-06-30 02:33:04] Saved K-mer Ens test results to results_msBERT_replication/test_results_kmer_ensemble.csv\n",
      "[2025-06-30 02:33:04] --- msBERT Replication Workflow Completed in 911644.50s (253.23 hrs) ---\n"
     ]
    }
   ],
   "source": [
    "# %% 7. Main Execution Block for msBERT-Promoter Replication\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    log_message_kmer(f\"--- Starting msBERT-Promoter Replication Workflow (PID: {os.getpid()}) ---\")\n",
    "    msbert_start_time = time.time()\n",
    "\n",
    "    class ArgsRep: pass\n",
    "    args_rep = ArgsRep()\n",
    "    args_rep.force_kmer_model_rebuild = False # Set True to retrain all k-mer models, even if checkpoints exist\n",
    "    args_rep.kmer_epochs = NUM_EPOCHS_KMER\n",
    "    args_rep.kmer_batch_size = BATCH_SIZE_KMER\n",
    "    args_rep.kmer_lr = LEARNING_RATE_KMER\n",
    "    # Example Override:\n",
    "    # args_rep.force_kmer_model_rebuild = True\n",
    "\n",
    "    log_message_kmer(f\"K-mer Baseline Config: Epochs={args_rep.kmer_epochs}, Batch={args_rep.kmer_batch_size}, LR={args_rep.kmer_lr}, ForceRebuild={args_rep.force_kmer_model_rebuild}\")\n",
    "\n",
    "    try:\n",
    "        log_message_kmer(\"\\n--- Step 1: Loading Raw Sequence Data ---\")\n",
    "        promoter_seqs_raw, promoter_labels_raw = load_raw_sequences_for_kmer(\n",
    "            PROMOTER_SEQ_FILE_REPLICATION, is_promoter=True, seq_len_expected=SEQ_LEN_FOR_KMER_LOADING)\n",
    "        nonpromoter_seqs_raw, nonpromoter_labels_raw = load_raw_sequences_for_kmer(\n",
    "            NON_PROMOTER_SEQ_FILE_REPLICATION, is_promoter=False, seq_len_expected=SEQ_LEN_FOR_KMER_LOADING)\n",
    "        if not promoter_seqs_raw or not nonpromoter_seqs_raw: raise ValueError(\"Failed to load raw sequences.\")\n",
    "        all_raw_sequences_for_kmer_baseline = promoter_seqs_raw + nonpromoter_seqs_raw\n",
    "        all_labels_for_kmer_baseline = promoter_labels_raw + nonpromoter_labels_raw\n",
    "        log_message_kmer(f\"Total raw sequences for k-mer models: {len(all_raw_sequences_for_kmer_baseline)}\")\n",
    "\n",
    "        log_message_kmer(\"\\n--- Step 2: Building K-mer Vocabularies ---\")\n",
    "        kmer_vocabs_map = build_kmer_vocab(all_raw_sequences_for_kmer_baseline, KMER_VALUES, kmer_stride_for_vocab=KMER_STRIDE)\n",
    "\n",
    "        max_kmer_seq_lens_map = {}\n",
    "        log_message_kmer(\"\\n--- Step 3: Calculating Max K-mer Sequence Lengths ---\")\n",
    "        for k_val_len in KMER_VALUES:\n",
    "            current_k_max_len = 0\n",
    "            for seq_len_calc in tqdm(all_raw_sequences_for_kmer_baseline, desc=f\"Max k-mer len for k={k_val_len}\"):\n",
    "                if isinstance(seq_len_calc, str):\n",
    "                    current_k_max_len = max(current_k_max_len, len(sequence_to_kmers(seq_len_calc, k_val_len, stride=KMER_STRIDE)))\n",
    "            max_kmer_seq_lens_map[k_val_len] = current_k_max_len if current_k_max_len > 0 else 1\n",
    "            log_message_kmer(f\"Max k-mer seq length for k={k_val_len}: {max_kmer_seq_lens_map[k_val_len]}\")\n",
    "\n",
    "        log_message_kmer(\"\\n--- Step 4: Training/Loading Individual K-mer Models ---\")\n",
    "        trained_kmer_models_dict = {}\n",
    "        kmer_full_dataset_size = len(all_raw_sequences_for_kmer_baseline)\n",
    "        kmer_all_indices = list(range(kmer_full_dataset_size))\n",
    "        np.random.seed(RANDOM_SEED); np.random.shuffle(kmer_all_indices)\n",
    "        k_test_split_idx = int(np.floor(TEST_SPLIT * kmer_full_dataset_size))\n",
    "        k_val_split_idx = k_test_split_idx + int(np.floor(VALIDATION_SPLIT * kmer_full_dataset_size))\n",
    "        k_test_indices = kmer_all_indices[:k_test_split_idx]\n",
    "        k_val_indices  = kmer_all_indices[k_test_split_idx:k_val_split_idx]\n",
    "        k_train_indices= kmer_all_indices[k_val_split_idx:]\n",
    "        if not k_train_indices or not k_val_indices or not k_test_indices: raise ValueError(\"K-mer dataset splitting error.\")\n",
    "        log_message_kmer(f\"K-mer Data Split: Train={len(k_train_indices)}, Val={len(k_val_indices)}, Test={len(k_test_indices)}\")\n",
    "\n",
    "        for k_val_run in KMER_VALUES:\n",
    "            log_message_kmer(f\"\\n--- Processing for k={k_val_run} ---\")\n",
    "            k_model_best_path_run = KMER_MODEL_BEST_SAVE_PATH_TPL.format(k=k_val_run)\n",
    "            k_loss_plot_path_run = KMER_LOSS_PLOT_PATH_TPL.format(k=k_val_run)\n",
    "            k_checkpoint_dir_run = KMER_CHECKPOINT_DIR_TPL.format(k=k_val_run) # Specific dir for this k\n",
    "\n",
    "            k_model_instance = KmerTransformer(\n",
    "                kmer_vocab_size=kmer_vocabs_map[k_val_run]['vocab_size'],\n",
    "                max_kmer_seq_len=max_kmer_seq_lens_map[k_val_run],\n",
    "                embed_dim=KMER_EMBED_DIM, num_heads=KMER_NUM_HEADS,\n",
    "                ff_dim=KMER_TRANSFORMER_FF_DIM, num_layers=KMER_NUM_TRANSFORMER_LAYERS,\n",
    "                dropout=KMER_DROPOUT_RATE, kmer_pad_idx=kmer_vocabs_map[k_val_run]['pad_idx']\n",
    "            ).to(DEVICE)\n",
    "            # log_message_kmer(f\"k={k_val_run} Initialized Model Params: {sum(p.numel() for p in k_model_instance.parameters() if p.requires_grad):,}\") # Verbose\n",
    "\n",
    "            # Skip training if best model AND plot exist AND not forcing rebuild\n",
    "            if os.path.exists(k_model_best_path_run) and os.path.exists(k_loss_plot_path_run) and not args_rep.force_kmer_model_rebuild:\n",
    "                log_message_kmer(f\"Found completed training for k={k_val_run} (best model & plot exist). Loading: {k_model_best_path_run}\")\n",
    "                try:\n",
    "                    k_model_instance.load_state_dict(torch.load(k_model_best_path_run, map_location=DEVICE))\n",
    "                    trained_kmer_models_dict[k_val_run] = k_model_instance\n",
    "                    log_message_kmer(f\"Successfully loaded best model for k={k_val_run}.\")\n",
    "                    continue # Skip to the next k-value\n",
    "                except Exception as e:\n",
    "                    log_message_kmer(f\"Error loading existing best model for k={k_val_run}: {e}. Will attempt to train/resume.\")\n",
    "            \n",
    "            temp_full_k_dataset = KmerDataset(all_raw_sequences_for_kmer_baseline, all_labels_for_kmer_baseline,\n",
    "                k_val_run, kmer_vocabs_map[k_val_run], max_kmer_seq_lens_map[k_val_run], kmer_stride_val=KMER_STRIDE)\n",
    "            k_train_subset = Subset(temp_full_k_dataset, k_train_indices)\n",
    "            k_val_subset = Subset(temp_full_k_dataset, k_val_indices)\n",
    "            k_num_workers = 0\n",
    "            k_train_loader_run = DataLoader(k_train_subset, batch_size=args_rep.kmer_batch_size, shuffle=True, num_workers=k_num_workers, drop_last=(len(k_train_subset) % args_rep.kmer_batch_size == 1 and len(k_train_subset)>1))\n",
    "            k_val_loader_run = DataLoader(k_val_subset, batch_size=args_rep.kmer_batch_size, shuffle=False, num_workers=k_num_workers)\n",
    "\n",
    "            k_criterion_run = nn.BCEWithLogitsLoss()\n",
    "            k_optimizer_run = optim.AdamW(k_model_instance.parameters(), lr=args_rep.kmer_lr, weight_decay=OPTIMIZER_WEIGHT_DECAY_KMER)\n",
    "            k_scheduler_run = optim.lr_scheduler.ReduceLROnPlateau(k_optimizer_run, 'min', factor=0.2, patience=3) \n",
    "\n",
    "            trained_model_k = train_kmer_model(\n",
    "                k_val_run, k_model_instance, k_train_loader_run, k_val_loader_run, k_criterion_run, k_optimizer_run,\n",
    "                args_rep.kmer_epochs, DEVICE, \n",
    "                KMER_MODEL_BEST_SAVE_PATH_TPL, # Pass template for best model\n",
    "                KMER_LOSS_PLOT_PATH_TPL,\n",
    "                k_scheduler_run,\n",
    "                checkpoint_dir_tpl_k=KMER_CHECKPOINT_DIR_TPL # Pass template for epoch checkpoints\n",
    "            )\n",
    "            trained_kmer_models_dict[k_val_run] = trained_model_k\n",
    "            if trained_model_k is None: log_message_kmer(f\"ERROR: Training/Resuming failed for k={k_val_run}.\")\n",
    "\n",
    "        log_message_kmer(\"\\n--- Step 5: Evaluating K-mer Ensemble ---\")\n",
    "        if any(model is None for model in trained_kmer_models_dict.values()):\n",
    "            log_message_kmer(\"Warning: One or more k-mer models missing. Ensemble results may be based on fewer models.\")\n",
    "        \n",
    "        valid_trained_k_models = {k: m for k, m in trained_kmer_models_dict.items() if m is not None}\n",
    "        valid_k_values_for_ensemble = list(valid_trained_k_models.keys())\n",
    "\n",
    "        if not valid_trained_k_models:\n",
    "            log_message_kmer(\"No k-mer models available for ensemble evaluation. Skipping.\")\n",
    "        else:\n",
    "            raw_test_sequences = [all_raw_sequences_for_kmer_baseline[i] for i in k_test_indices]\n",
    "            raw_test_labels = [all_labels_for_kmer_baseline[i] for i in k_test_indices]\n",
    "            ensemble_test_dataset = RawSequenceDatasetForEnsemble(raw_test_sequences, raw_test_labels)\n",
    "            ensemble_test_loader = DataLoader(ensemble_test_dataset, batch_size=args_rep.kmer_batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "            evaluate_kmer_ensemble(valid_trained_k_models, ensemble_test_loader, valid_k_values_for_ensemble,\n",
    "                                   kmer_vocabs_map, max_kmer_seq_lens_map, DEVICE,\n",
    "                                   kmer_stride_for_eval=KMER_STRIDE,\n",
    "                                   results_csv_path_ens=ENSEMBLE_RESULTS_CSV_PATH,\n",
    "                                   cm_plot_path_base_ens=ENSEMBLE_CM_PLOT_PATH_BASE)\n",
    "\n",
    "        total_msbert_duration = time.time() - msbert_start_time\n",
    "        log_message_kmer(f\"--- msBERT Replication Workflow Completed in {total_msbert_duration:.2f}s ({total_msbert_duration/3600:.2f} hrs) ---\")\n",
    "\n",
    "    except FileNotFoundError as fnf_error: log_message_kmer(f\"\\nKMER WORKFLOW FileNotFoundError: {fnf_error}\")\n",
    "    except ValueError as val_error: log_message_kmer(f\"\\nKMER WORKFLOW ValueError: {val_error}\\n{traceback.format_exc()}\")\n",
    "    except RuntimeError as rt_error: log_message_kmer(f\"\\nKMER WORKFLOW RuntimeError: {rt_error}\\n{traceback.format_exc()}\")\n",
    "    except Exception as main_error: log_message_kmer(f\"\\nKMER WORKFLOW Exception: {type(main_error).__name__}: {main_error}\\n{traceback.format_exc()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad2d3d8-580a-4494-bbf2-02d35a1a68d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca08ad-f03e-48e9-a3ea-9fdc59ab711c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a753f-5e93-490e-b03d-21c00e441f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d4f69c-8110-448f-a0f5-3193f9df2f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec31c2f-74d4-48ac-881d-a0da59f2a64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39efe626-9a1a-4770-b4b4-636b43862166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11f14b-8a95-4b8a-8c1a-6ca6a580e0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
