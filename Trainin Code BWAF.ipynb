{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e47f21b7-e757-4efe-bd74-2cfc2a75c61c",
   "metadata": {},
   "source": [
    "# **Supplementary Code: BWAF Multi-Modal Promoter Prediction Framework**\n",
    "\n",
    "**Description:**\n",
    "This notebook provides the complete Python implementation for the research thesis titled: **\"Biologically Weighted Dynamic Fusion of Transformer and Graph Attention Networks for Promoter Region Identification in the Human Genome Using Multi-Omics Data\"**.\n",
    "\n",
    "The code implements a multi-modal deep learning pipeline integrating:\n",
    "1.  **Genomic Sequences:** Processed using a Transformer network.\n",
    "2.  **Gene-TF Interaction Networks:** From the GRAND database (36 tissues), processed using Graph Attention Networks (GATs). The GATs operate on **Gene-Gene graphs** derived from TF co-regulation patterns within each tissue.\n",
    "3.  **Biological Priors:** Derived from promoter motif counts, log-transformed.\n",
    "\n",
    "A key novelty is the **Biologically Weighted Attention Fusion (BWAF)** layer, which uses biological priors to dynamically modulate the fusion of sequence and network features. The pipeline includes data loading, extensive preprocessing (including a refined GAT edge index creation strategy with optional edge capping), model definition, training, and evaluation routines.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Imports**\n",
    "\n",
    "This section imports all necessary libraries for data manipulation (Pandas, NumPy), deep learning (PyTorch, PyTorch Geometric), machine learning evaluation (scikit-learn), plotting (Matplotlib, Seaborn), and system utilities (os, glob, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f1fb721-a251-49e4-8e26-04289ff8d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 1. Imports\n",
    "# ============================================================================\n",
    "# Standard library imports\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import gzip\n",
    "import time\n",
    "import argparse\n",
    "import datetime\n",
    "import sys\n",
    "import warnings\n",
    "import random # Ensure random is imported\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split # Used for splitting indices\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                           f1_score, roc_auc_score, confusion_matrix)\n",
    "from scipy.sparse import coo_matrix # For sparse matrix operations if needed elsewhere\n",
    "from tqdm.notebook import tqdm # Use notebook version for Jupyter\n",
    "# from tqdm import tqdm # Use standard tqdm otherwise\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch Geometric imports\n",
    "try:\n",
    "    from torch_geometric.nn import GATConv\n",
    "    from torch_geometric.utils import from_scipy_sparse_matrix # Useful for converting scipy sparse to edge_index\n",
    "except ImportError:\n",
    "    print(\"PyTorch Geometric not found. Please install it: https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html\")\n",
    "    raise ImportError(\"PyTorch Geometric is required but not found.\")\n",
    "\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='torch_geometric.nn.conv.gat_conv')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='torch_geometric.nn.conv.gatv2_conv')\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.DtypeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dded35bd-f139-4b01-bded-5cd7c108dc70",
   "metadata": {},
   "source": [
    "## **2. Configuration / Constants**\n",
    "\n",
    "This section defines crucial parameters and file paths used throughout the script. **Users must verify and potentially modify the `Data Paths` section** to match their local environment. Hyperparameters for the model and training process are also set here, allowing for easy modification and experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65e65b6-c41c-4fec-acc8-6f3f19c2f213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 2. Configuration / Constants\n",
    "# ============================================================================\n",
    "# --- Data Paths ---\n",
    "# !!! USER MUST MODIFY THESE PATHS !!!\n",
    "BASE_DATA_DIR = 'data/' # Modify to your base data directory\n",
    "SEQ_DATA_DIR = os.path.join(BASE_DATA_DIR, 'raw/human_genome_annotation')\n",
    "PRIOR_DATA_DIR = os.path.join(BASE_DATA_DIR, 'raw/human_genome_annotation')\n",
    "GAT_RAW_DATA_DIR = os.path.join(BASE_DATA_DIR, 'raw/gene_interaction_network/GRAND_networks') # Where GRAND *.csv are (UNNORMALIZED)\n",
    "GAT_PREPROCESSED_DIR = os.path.join(BASE_DATA_DIR, 'preprocessed/gat_normalized') # Filtered/normalized output\n",
    "GAT_EDGE_INDEX_DIR = os.path.join(BASE_DATA_DIR, 'preprocessed/gat_edge_indices') # Edge index output\n",
    "\n",
    "PROMOTER_SEQ_FILE = os.path.join(SEQ_DATA_DIR, 'updated_promoter_features_clean.csv')\n",
    "NON_PROMOTER_SEQ_FILE = os.path.join(SEQ_DATA_DIR, 'updated_non_promoter_sequences.csv') # Ensure this file exists\n",
    "PRIOR_FILE = os.path.join(PRIOR_DATA_DIR, 'biological_prior_for_transformer_branch.csv')\n",
    "\n",
    "# --- Model Hyperparameters ---\n",
    "SEQ_LEN = 2000\n",
    "NUCLEOTIDES = ['A', 'T', 'C', 'G']\n",
    "PAD_IDX = 4\n",
    "VOCAB_SIZE = len(NUCLEOTIDES) + 1\n",
    "\n",
    "EMBEDDING_DIM = 64 # Dimension for Transformer output and GAT output\n",
    "NUM_ATTN_HEADS = 4 # Transformer MHA heads\n",
    "NUM_TRANSFORMER_LAYERS = 2\n",
    "TRANSFORMER_FF_DIM = EMBEDDING_DIM * 4\n",
    "\n",
    "NUM_GAT_LAYERS = 1 # Number of GAT layers per tissue\n",
    "NUM_TISSUES = 36 # Number of tissue-specific networks to process\n",
    "GAT_HEADS = 4 # GAT MHA heads (intermediate layers if NUM_GAT_LAYERS > 1)\n",
    "GAT_FINAL_HEADS = 1 # GAT final layer heads (output averaged if > 1 and concat=False)\n",
    "\n",
    "GAT_INTERACTION_THRESHOLD_STD_FACTOR = 2.5\n",
    "MAX_EDGES_PER_TISSUE_APPROX = 1000000 # Approx. 1M undirected edges (2M directed)\n",
    "\n",
    "# BWAF Fusion Layer specific\n",
    "FUSION_HIDDEN_DIM = 128 # Hidden dimension within the fusion classifier part\n",
    "\n",
    "# General\n",
    "DROPOUT_RATE = 0.3\n",
    "\n",
    "# --- Training Hyperparameters ---\n",
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10 # Adjust as needed\n",
    "VALIDATION_SPLIT = 0.15\n",
    "TEST_SPLIT = 0.15\n",
    "RANDOM_SEED = 42\n",
    "OPTIMIZER_WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# --- Output Files ---\n",
    "OUTPUT_DIR = 'results_bwaf_v3/' # New directory for this version's results\n",
    "MODEL_SAVE_PATH = os.path.join(OUTPUT_DIR, 'best_promoter_model_bwaf.pth')\n",
    "LOSS_PLOT_PATH = os.path.join(OUTPUT_DIR, 'training_validation_loss_bwaf.png')\n",
    "CONFUSION_MATRIX_PATH = os.path.join(OUTPUT_DIR, 'confusion_matrix_bwaf.png')\n",
    "RESULTS_CSV_PATH = os.path.join(OUTPUT_DIR, 'test_set_evaluation_results_bwaf.csv')\n",
    "LOG_FILE_PATH = os.path.join(OUTPUT_DIR, 'training_log_bwaf.txt')\n",
    "\n",
    "# --- Hardware ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Setup ---\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
    "os.makedirs(GAT_PREPROCESSED_DIR, exist_ok=True)\n",
    "os.makedirs(GAT_EDGE_INDEX_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683f465-6ea6-445c-8774-69e810814fd7",
   "metadata": {},
   "source": [
    "## **3. Utility Functions**\n",
    "\n",
    "This section contains helper functions for logging, DNA sequence encoding, log-transformation of priors, and standardized gene ID extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd71624a-3318-4693-99f8-7b539c7ee084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-04 18:28:51] Log file started at: results_bwaf_v3/training_log_bwaf.txt\n",
      "[2025-06-04 18:28:51] Using device: cpu\n",
      "[2025-06-04 18:28:51] Random Seed: 42\n"
     ]
    }
   ],
   "source": [
    "# %% 3. Utility Functions\n",
    "# ============================================================================\n",
    "# --- Logging ---\n",
    "def log_message(message, log_file=LOG_FILE_PATH):\n",
    "    \"\"\"Appends a timestamped message to the log file and prints it.\"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    full_message = f\"[{timestamp}] {message}\"\n",
    "    print(full_message)\n",
    "    log_dir = os.path.dirname(log_file)\n",
    "    if log_dir and not os.path.exists(log_dir): os.makedirs(log_dir)\n",
    "    try:\n",
    "        with open(log_file, 'a', encoding='utf-8') as f: f.write(full_message + '\\n')\n",
    "    except IOError as e: print(f\"Error writing log: {e}\")\n",
    "\n",
    "try: # Initialize Log File\n",
    "    with open(LOG_FILE_PATH, 'w', encoding='utf-8') as f: f.write(f\"--- BWAF Training Log Initialized: {datetime.datetime.now()} ---\\n\")\n",
    "    log_message(f\"Log file started at: {LOG_FILE_PATH}\")\n",
    "except IOError as e: print(f\"CRITICAL ERROR: Could not write initial log file {LOG_FILE_PATH}: {e}\"); sys.exit(1)\n",
    "\n",
    "log_message(f\"Using device: {DEVICE}\")\n",
    "log_message(f\"Random Seed: {RANDOM_SEED}\")\n",
    "\n",
    "# --- Data Processing ---\n",
    "def integer_encode_sequence(sequence, max_len=SEQ_LEN):\n",
    "    \"\"\"Encodes a DNA sequence (string) into integer indices for PyTorch nn.Embedding.\"\"\"\n",
    "    encoding_map = {'A': 0, 'T': 1, 'C': 2, 'G': 3}\n",
    "    encoded = np.full(max_len, PAD_IDX, dtype=np.int64)\n",
    "    seq_len_actual = min(len(sequence), max_len)\n",
    "    n_unmapped = 0\n",
    "    for i, nucleotide in enumerate(sequence[:seq_len_actual]):\n",
    "        idx = encoding_map.get(nucleotide.upper())\n",
    "        if idx is not None: encoded[i] = idx\n",
    "        else:\n",
    "            encoded[i] = PAD_IDX\n",
    "            if nucleotide.upper() != 'N' and n_unmapped < 5: # Log first few unexpected chars\n",
    "                 log_message(f\"Warning: Non-ATCGN char '{nucleotide}' at pos {i}. Mapped to PAD_IDX.\")\n",
    "                 n_unmapped += 1\n",
    "    return encoded\n",
    "\n",
    "def log_transform_priors(prior_counts):\n",
    "    \"\"\"Applies log(1+x) transformation element-wise to biological prior counts.\"\"\"\n",
    "    if not isinstance(prior_counts, np.ndarray): prior_counts = np.array(prior_counts)\n",
    "    prior_counts[prior_counts < 0] = 0\n",
    "    return np.log1p(prior_counts.astype(np.float32))\n",
    "\n",
    "def extract_clean_gene_id(raw_id_series):\n",
    "    \"\"\"Uses regex (r'(ENSG\\d+)') to extract the Ensembl Gene ID from a pandas Series.\"\"\"\n",
    "    if not isinstance(raw_id_series, pd.Series): raw_id_series = pd.Series(raw_id_series)\n",
    "    return raw_id_series.astype(str).str.extract(r'(ENSG\\d+)', expand=False).fillna('UNKNOWN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05ca0e3-89ba-41d0-813c-6bb81e7732e0",
   "metadata": {},
   "source": [
    "## **4. Data Loading Functions**\n",
    "\n",
    "These functions handle loading and preprocessing for sequences, priors, and GAT network data.\n",
    "*   `load_sequences`: Loads, QCs, and labels sequences.\n",
    "*   `load_priors`: Loads, aligns, and log-transforms motif counts.\n",
    "*   `_preprocess_and_save_gat_matrix`: Helper to filter and MinMax normalize raw GAT matrices, ensuring consistent TF and Gene orders.\n",
    "*   `preprocess_all_gat_data`: Orchestrates GAT matrix preprocessing and determines master TF list.\n",
    "*   `load_processed_gat_data`: Loads normalized GAT data and creates initial node features (average TF interaction profiles).\n",
    "*   `load_or_create_edge_indices`: **Refined function to create Gene-Gene graphs.** Edges connect genes co-regulated by the same TF above a TF-specific dynamic threshold, with an optional cap on total edges per tissue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f92fa0b-8c25-4e1b-8d5e-61c6049f2d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 4. Data Loading Functions\n",
    "# ============================================================================\n",
    "\n",
    "def load_sequences(file_path, is_promoter=True):\n",
    "    \"\"\"Loads sequences, performs QC (N removal, length check), assigns labels, handles encodings.\"\"\"\n",
    "    log_message(f\"Loading sequences from {file_path}...\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        if not os.path.exists(file_path): raise FileNotFoundError(f\"Sequence file not found: {file_path}\")\n",
    "        df = None; encodings_to_try = ['utf-8', 'ISO-8859-1', 'latin1']\n",
    "        for encoding in encodings_to_try:\n",
    "            try: df = pd.read_csv(file_path, encoding=encoding, low_memory=False); break\n",
    "            except (UnicodeDecodeError, pd.errors.ParserError): pass\n",
    "        if df is None: raise ValueError(f\"Could not read {file_path} with attempted encodings.\")\n",
    "\n",
    "        seq_col, id_col = None, None\n",
    "        possible_seq_cols = ['promoter_sequence', 'sequence']\n",
    "        possible_id_cols = ['gene_id', df.columns[0] if not df.empty else None]\n",
    "\n",
    "        for col in possible_seq_cols:\n",
    "            if col in df.columns: seq_col = col; break\n",
    "        for col in possible_id_cols:\n",
    "            if col in df.columns: id_col = col; break\n",
    "        if seq_col is None or id_col is None: raise ValueError(f\"Required columns not in {file_path}. Cols: {df.columns.tolist()}\")\n",
    "\n",
    "        df[seq_col] = df[seq_col].astype(str); df['clean_gene_id'] = extract_clean_gene_id(df[id_col])\n",
    "        df.dropna(subset=['clean_gene_id', seq_col], inplace=True); df = df[df['clean_gene_id'] != 'UNKNOWN']; df = df[df[seq_col].str.strip() != '']\n",
    "\n",
    "        initial_qc_count = len(df)\n",
    "        df = df[~df[seq_col].str.contains('N', na=False, case=False)]; removed_n = initial_qc_count - len(df)\n",
    "        initial_qc_count = len(df)\n",
    "        # Only check length if SEQ_LEN is defined and positive\n",
    "        if SEQ_LEN and SEQ_LEN > 0:\n",
    "            df['seq_len_actual'] = df[seq_col].str.len()\n",
    "            df = df[df['seq_len_actual'] == SEQ_LEN]; removed_len = initial_qc_count - len(df)\n",
    "            df = df.drop(columns=['seq_len_actual'])\n",
    "            log_message(f\"Sequence QC for {os.path.basename(file_path)}: Total initial: {len(df) + removed_n + removed_len}. Removed {removed_n} (with 'N'). Removed {removed_len} (not {SEQ_LEN}bp). Final: {len(df)}.\")\n",
    "        else:\n",
    "            log_message(f\"Sequence QC for {os.path.basename(file_path)}: Total initial: {len(df) + removed_n}. Removed {removed_n} (with 'N'). Length check skipped. Final: {len(df)}.\")\n",
    "\n",
    "\n",
    "        if df.empty: log_message(f\"Warning: No valid sequences in {file_path}.\"); return [], [], []\n",
    "        sequences = df[seq_col].tolist(); gene_ids = df['clean_gene_id'].tolist(); labels = [1 if is_promoter else 0] * len(sequences)\n",
    "        log_message(f\"Loaded and filtered {len(sequences)} sequences from {os.path.basename(file_path)} in {time.time() - start_time:.2f}s.\")\n",
    "        return sequences, gene_ids, labels\n",
    "    except Exception as e: log_message(f\"CRITICAL ERROR loading sequence file {file_path}: {e}\"); raise\n",
    "\n",
    "def load_priors(file_path, gene_id_order):\n",
    "    \"\"\"Loads priors, aligns, log-transforms.\"\"\"\n",
    "    log_message(f\"Loading priors from {file_path}...\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        if not os.path.exists(file_path): raise FileNotFoundError(f\"Prior file not found: {file_path}\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'gene_id' not in df.columns: raise ValueError(\"'gene_id' column missing in prior file.\")\n",
    "        df['clean_gene_id'] = extract_clean_gene_id(df['gene_id'])\n",
    "        df.dropna(subset=['clean_gene_id'], inplace=True); df = df[df['clean_gene_id'] != 'UNKNOWN']\n",
    "        count_columns = [col for col in df.columns if '(Count)' in col]\n",
    "        if not count_columns: raise ValueError(\"No prior count columns found in prior file.\")\n",
    "        prior_dim = len(count_columns); log_message(f\"Found {prior_dim} prior count columns.\")\n",
    "        df_priors = df[['clean_gene_id'] + count_columns].copy()\n",
    "        for col in count_columns: df_priors[col] = pd.to_numeric(df_priors[col], errors='coerce')\n",
    "        df_priors.fillna(0, inplace=True)\n",
    "        df_priors.set_index('clean_gene_id', inplace=True)\n",
    "        df_priors = df_priors[~df_priors.index.duplicated(keep='first')]\n",
    "        aligned_df = df_priors.reindex(gene_id_order, fill_value=0)\n",
    "        log_transformed_priors = log_transform_priors(aligned_df.values)\n",
    "        log_message(f\"Processed priors for {log_transformed_priors.shape[0]} genes in {time.time() - start_time:.2f}s.\")\n",
    "        return log_transformed_priors, prior_dim\n",
    "    except Exception as e: log_message(f\"CRITICAL ERROR processing prior file {file_path}: {e}\"); raise\n",
    "\n",
    "def _preprocess_and_save_gat_matrix(raw_file_path, output_file_path, gene_id_order_master_unique, master_tf_ids_list=None):\n",
    "    \"\"\"Internal: Filters raw GAT matrix by unique gene_id_order and master_tf_ids_list, normalizes, saves.\"\"\"\n",
    "    try:\n",
    "        df_raw = pd.read_csv(raw_file_path, index_col=0)\n",
    "        if df_raw.columns.has_duplicates: df_raw = df_raw.loc[:, ~df_raw.columns.duplicated(keep='first')]\n",
    "        current_tf_ids_raw = df_raw.index.tolist()\n",
    "        if master_tf_ids_list is None: master_tf_ids_list = current_tf_ids_raw\n",
    "\n",
    "        df_tf_aligned = df_raw.reindex(index=master_tf_ids_list, fill_value=0.0)\n",
    "        master_gene_set_unique = set(gene_id_order_master_unique)\n",
    "        common_genes_in_raw_order = [gene for gene in df_tf_aligned.columns if gene in master_gene_set_unique]\n",
    "\n",
    "        if not common_genes_in_raw_order:\n",
    "            df_gene_aligned = pd.DataFrame(0.0, index=master_tf_ids_list, columns=gene_id_order_master_unique)\n",
    "        else:\n",
    "            df_gene_aligned = df_tf_aligned[common_genes_in_raw_order]\n",
    "            df_gene_aligned = df_gene_aligned.reindex(columns=gene_id_order_master_unique, fill_value=0.0)\n",
    "\n",
    "        numeric_data = df_gene_aligned.values.astype(np.float32)\n",
    "        min_val, max_val = np.min(numeric_data), np.max(numeric_data)\n",
    "        range_val = max_val - min_val\n",
    "        normalized_values = np.zeros_like(numeric_data) if range_val < 1e-9 else (numeric_data - min_val) / (range_val + 1e-9)\n",
    "        df_normalized_aligned = pd.DataFrame(normalized_values, index=master_tf_ids_list, columns=gene_id_order_master_unique)\n",
    "        df_normalized_aligned.to_csv(output_file_path, compression='gzip')\n",
    "        return df_normalized_aligned, master_tf_ids_list, df_normalized_aligned.columns.tolist()\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error in _preprocess_and_save_gat_matrix for {raw_file_path}: {e}\")\n",
    "        import traceback; log_message(traceback.format_exc())\n",
    "        return None, master_tf_ids_list, None\n",
    "\n",
    "def preprocess_all_gat_data(raw_data_dir, processed_data_dir, gene_id_order_master_unique, force_preprocess=False):\n",
    "    \"\"\"Filters & normalizes GAT matrices, establishes master TF list.\"\"\"\n",
    "    log_message(f\"Preprocessing GAT data: {raw_data_dir} -> {processed_data_dir}\")\n",
    "    os.makedirs(processed_data_dir, exist_ok=True)\n",
    "    raw_files = sorted(glob.glob(os.path.join(raw_data_dir, '*.csv')))\n",
    "    if not raw_files: raise FileNotFoundError(f\"No raw GAT *.csv files in {raw_data_dir}\")\n",
    "\n",
    "    expected_processed = [os.path.join(processed_data_dir, f\"normalized_{os.path.basename(f)}.gz\") for f in raw_files]\n",
    "    all_exist = all(os.path.exists(f) for f in expected_processed)\n",
    "    master_tfs_determined = None; num_genes_aligned = len(gene_id_order_master_unique)\n",
    "\n",
    "    if all_exist and not force_preprocess:\n",
    "        log_message(\"Processed GAT files found. Verifying TF/Gene alignment...\")\n",
    "        try:\n",
    "            df_sample = pd.read_csv(expected_processed[0], index_col=0, compression='gzip')\n",
    "            master_tfs_determined = df_sample.index.tolist()\n",
    "            if df_sample.columns.tolist() != gene_id_order_master_unique:\n",
    "                 log_message(\"CRITICAL: Existing processed GAT columns DO NOT match master gene order. Forcing re-preprocess.\"); force_preprocess = True\n",
    "        except Exception as e: log_message(f\"Error reading sample: {e}. Forcing re-preprocess.\"); force_preprocess = True\n",
    "    \n",
    "    if not all_exist or force_preprocess: # Condition to enter processing loop\n",
    "        if all_exist and force_preprocess: log_message(\"Forcing re-preprocessing of GAT files...\")\n",
    "        else: log_message(\"Processing raw GAT files (filter/normalize)...\")\n",
    "\n",
    "        processed_count = 0\n",
    "        for i, raw_fp in enumerate(tqdm(raw_files, desc=\"Preprocessing GAT matrices\")):\n",
    "            out_fp = os.path.join(processed_data_dir, f\"normalized_{os.path.basename(raw_fp)}.gz\")\n",
    "            _, current_tfs_list, _ = _preprocess_and_save_gat_matrix(raw_fp, out_fp, gene_id_order_master_unique, master_tfs_determined)\n",
    "            if current_tfs_list is not None:\n",
    "                processed_count += 1\n",
    "                if master_tfs_determined is None: # First successful processing sets the master\n",
    "                    master_tfs_determined = current_tfs_list\n",
    "                    log_message(f\"Master TF list ({len(master_tfs_determined)} TFs) set from {os.path.basename(raw_fp)}\")\n",
    "                elif master_tfs_determined != current_tfs_list: # Should not happen if alignment is correct in _preprocess...\n",
    "                    log_message(f\"Warning: TF list from {os.path.basename(raw_fp)} differs from master after alignment.\")\n",
    "        if processed_count == 0 or master_tfs_determined is None: raise ValueError(\"Failed to process GAT files or determine master TFs.\")\n",
    "        if processed_count != len(raw_files): log_message(f\"Warning: Processed {processed_count}/{len(raw_files)} raw GAT files.\")\n",
    "\n",
    "    num_tfs_final = len(master_tfs_determined) if master_tfs_determined else 0\n",
    "    log_message(f\"GAT preprocessing complete. Master TFs: {num_tfs_final}, Aligned Genes: {num_genes_aligned}\")\n",
    "    return num_tfs_final, num_genes_aligned, gene_id_order_master_unique, master_tfs_determined\n",
    "\n",
    "def load_processed_gat_data(processed_data_dir, final_gene_order_gat, master_tf_ids_list):\n",
    "    \"\"\"Loads preprocessed (normalized & aligned) GAT matrices for initial node features.\"\"\"\n",
    "    log_message(f\"Loading processed GAT data from {processed_data_dir} (aligning to {len(final_gene_order_gat)} genes, {len(master_tf_ids_list)} TFs)...\")\n",
    "    start_time = time.time()\n",
    "    processed_files = sorted(glob.glob(os.path.join(processed_data_dir, 'normalized_*.csv.gz')))\n",
    "    if not processed_files: raise FileNotFoundError(f\"No processed GAT files in {processed_data_dir}\")\n",
    "\n",
    "    actual_tissues_found = len(processed_files)\n",
    "    global NUM_TISSUES_EFFECTIVE # To pass to GATNetwork\n",
    "    NUM_TISSUES_EFFECTIVE = actual_tissues_found\n",
    "    if actual_tissues_found != NUM_TISSUES:\n",
    "        log_message(f\"Note: Found {actual_tissues_found} processed GAT files. NUM_TISSUES config is {NUM_TISSUES}. Effective tissues: {NUM_TISSUES_EFFECTIVE}.\")\n",
    "\n",
    "    all_tissue_matrices = []; num_tfs_expected = len(master_tf_ids_list); num_genes_expected = len(final_gene_order_gat)\n",
    "    for file_path in tqdm(processed_files, desc=\"Loading processed GAT matrices\"):\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, index_col=0, compression='gzip')\n",
    "            # Re-confirm TF and Gene alignment (should be correct if preprocessing was done right)\n",
    "            df = df.reindex(index=master_tf_ids_list, columns=final_gene_order_gat, fill_value=0.0)\n",
    "            if df.shape != (num_tfs_expected, num_genes_expected):\n",
    "                log_message(f\"CRITICAL Shape Mismatch: {file_path} has {df.shape}, expected ({num_tfs_expected},{num_genes_expected}).\")\n",
    "            all_tissue_matrices.append(torch.tensor(df.values, dtype=torch.float32))\n",
    "        except Exception as e: log_message(f\"Error loading GAT file {file_path}: {e}\"); raise\n",
    "\n",
    "    if not all_tissue_matrices: raise ValueError(\"Failed to load GAT matrices.\")\n",
    "    all_tissue_tensors = torch.stack(all_tissue_matrices, dim=0)\n",
    "    avg_interactions_tf_gene = all_tissue_tensors.mean(dim=0)\n",
    "    initial_node_features = avg_interactions_tf_gene.T\n",
    "    elapsed = time.time() - start_time\n",
    "    log_message(f\"Loaded {len(all_tissue_matrices)} GAT matrices, created initial node features in {elapsed:.2f}s.\")\n",
    "    return initial_node_features, num_tfs_expected\n",
    "\n",
    "def load_or_create_edge_indices(\n",
    "    num_genes_in_graph, num_tfs_in_raw, num_tissues_to_process, # num_tissues_to_process should be NUM_TISSUES_EFFECTIVE\n",
    "    raw_gat_data_dir, gene_order_for_raw_alignment, edge_index_dir,\n",
    "    threshold_std_factor, force_rebuild=False, max_edges_per_tissue_approx=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Refined: Loads or creates Gene-Gene graph edge indices for each tissue.\n",
    "    Edges connect genes if they are co-regulated by the same TF above a TF-specific dynamic threshold.\n",
    "    \"\"\"\n",
    "    log_message(f\"GAT Edge Indices (TF Co-reg Gene-Gene, ThrFactor: {threshold_std_factor}, MaxEdges: {max_edges_per_tissue_approx})...\")\n",
    "    os.makedirs(edge_index_dir, exist_ok=True); edge_indices_list = []\n",
    "    raw_files_found = sorted(glob.glob(os.path.join(raw_gat_data_dir, '*.csv')))\n",
    "    if not raw_files_found: raise FileNotFoundError(f\"No raw GAT files in {raw_gat_data_dir}\")\n",
    "\n",
    "    actual_tissues_avail = len(raw_files_found)\n",
    "    # Use num_tissues_to_process passed from main, which is NUM_TISSUES_EFFECTIVE\n",
    "    files_to_loop = raw_files_found[:min(num_tissues_to_process, actual_tissues_avail)]\n",
    "\n",
    "    if len(files_to_loop) != num_tissues_to_process:\n",
    "        log_message(f\"Warning: Will create edge indices for {len(files_to_loop)} tissues (based on raw files), not {num_tissues_to_process}.\")\n",
    "\n",
    "    for raw_file_path in tqdm(files_to_loop, desc=\"Creating Gene-Gene edge indices\"):\n",
    "        tissue_name = os.path.basename(raw_file_path).replace('.csv', '')\n",
    "        fname_suffix = f\"_gg_th{threshold_std_factor:.1f}\" + (f\"_maxE{max_edges_per_tissue_approx//1000}k\" if max_edges_per_tissue_approx else \"\") + \".pt\"\n",
    "        edge_index_file = os.path.join(edge_index_dir, tissue_name + fname_suffix)\n",
    "        current_edge_index = None\n",
    "\n",
    "        if os.path.exists(edge_index_file) and not force_rebuild:\n",
    "            try: current_edge_index = torch.load(edge_index_file)\n",
    "            except: log_message(f\"Error loading {edge_index_file}. Recreating.\"); current_edge_index = None\n",
    "        \n",
    "        if current_edge_index is None:\n",
    "            # log_message(f\"Creating Gene-Gene edge index for {tissue_name}...\") # Can be too verbose\n",
    "            try:\n",
    "                if not os.path.exists(raw_file_path): raise FileNotFoundError(f\"Raw file missing: {raw_file_path}\")\n",
    "                df_raw = pd.read_csv(raw_file_path, index_col=0)\n",
    "                # Ensure row (TF) alignment to the master list of TFs determined from preprocessing\n",
    "                # This uses num_tfs_in_raw for the expected count from the *master* TF list.\n",
    "                # df_raw_tf_aligned = df_raw.reindex(index=master_tf_ids_list_from_preprocessing, fill_value=0.0) \n",
    "                # The above is complex if master_tf_ids_list_from_preprocessing isn't available here easily.\n",
    "                # Assuming df_raw has the TFs we care about (num_tfs_in_raw of them)\n",
    "                if df_raw.shape[0] != num_tfs_in_raw:\n",
    "                    log_message(f\"Warning: Raw TF count in {tissue_name} ({df_raw.shape[0]}) \"\n",
    "                                f\"differs from expected master TF count ({num_tfs_in_raw}) for edge creation.\")\n",
    "                    # Decide on handling: reindex to master_tfs, or use available TFs in file?\n",
    "                    # For now, proceed with TFs available in the file, but this means num_tfs_in_raw might vary by file in this loop.\n",
    "                    # This part needs careful sync with how num_tfs_in_raw is passed.\n",
    "\n",
    "                df_raw_aligned_cols = df_raw.reindex(columns=gene_order_for_raw_alignment, fill_value=0.0)\n",
    "                if df_raw_aligned_cols.shape[1] != num_genes_in_graph: raise ValueError(f\"Gene alignment error for {tissue_name}\")\n",
    "\n",
    "                abs_scores_matrix = np.abs(df_raw_aligned_cols.values) # (N_tfs_in_file, N_genes_in_graph)\n",
    "                all_gene_pairs = set()\n",
    "\n",
    "                for tf_idx in range(df_raw_aligned_cols.shape[0]): # Iterate over TFs IN THIS FILE\n",
    "                    tf_scores = abs_scores_matrix[tf_idx, :]\n",
    "                    non_zero_tf = tf_scores[tf_scores > 1e-6] # Consider scores effectively non-zero\n",
    "                    if non_zero_tf.size < 2: continue # Need at least two genes for a pair\n",
    "\n",
    "                    mean_tf = np.mean(non_zero_tf); std_tf = np.std(non_zero_tf)\n",
    "                    robust_std_tf = max(std_tf, 1e-3 * (mean_tf if mean_tf > 1e-6 else 0.1)) # Avoid zero std\n",
    "                    tf_specific_threshold = mean_tf + threshold_std_factor * robust_std_tf\n",
    "                    \n",
    "                    strongly_regulated_indices = np.where(tf_scores > tf_specific_threshold)[0]\n",
    "                    if len(strongly_regulated_indices) >= 2:\n",
    "                        genes_list = list(strongly_regulated_indices)\n",
    "                        for i in range(len(genes_list)):\n",
    "                            for j in range(i + 1, len(genes_list)):\n",
    "                                all_gene_pairs.add(tuple(sorted((genes_list[i], genes_list[j]))))\n",
    "                                if max_edges_per_tissue_approx and len(all_gene_pairs) > max_edges_per_tissue_approx * 1.1: break\n",
    "                            if max_edges_per_tissue_approx and len(all_gene_pairs) > max_edges_per_tissue_approx * 1.1: break\n",
    "                    if max_edges_per_tissue_approx and len(all_gene_pairs) > max_edges_per_tissue_approx * 1.1: break\n",
    "                \n",
    "                if max_edges_per_tissue_approx and len(all_gene_pairs) > max_edges_per_tissue_approx:\n",
    "                    all_gene_pairs = set(random.sample(list(all_gene_pairs), max_edges_per_tissue_approx))\n",
    "                \n",
    "                src, trg = [], []\n",
    "                for g1, g2 in all_gene_pairs: src.extend([g1,g2]); trg.extend([g2,g1])\n",
    "                \n",
    "                if src: current_edge_index = torch.tensor(np.vstack((src, trg)), dtype=torch.long)\n",
    "                else: current_edge_index = torch.empty((2,0), dtype=torch.long)\n",
    "                \n",
    "                torch.save(current_edge_index, edge_index_file)\n",
    "                # log_message(f\"Saved Gene-Gene edge index for {tissue_name} ({len(all_gene_pairs)} undir edges) to {edge_index_file}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                log_message(f\"Error creating edge index for {tissue_name}: {e}\")\n",
    "                current_edge_index = torch.empty((2,0), dtype=torch.long) # Empty on error\n",
    "        \n",
    "        edge_indices_list.append(current_edge_index)\n",
    "\n",
    "    log_message(f\"Finished processing {len(edge_indices_list)} Gene-Gene edge indices.\")\n",
    "    return edge_indices_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8172db80-9a7c-4734-b5cf-70fbac55a2f7",
   "metadata": {},
   "source": [
    "## **5. PyTorch Dataset Class**\n",
    "\n",
    "The `PromoterGATDataset` class prepares individual samples for the model. It stores integer-encoded sequences, log-transformed prior features, and binary labels. A key function is to provide `aligned_gat_idx` for each sample, which maps the gene ID to the correct row in the precomputed GAT output tensor, enabling feature selection in the `FullModel`'s forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee4c0577-5ea4-4e5a-bf19-f3722f15b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 5. PyTorch Dataset Class\n",
    "# ============================================================================\n",
    "class PromoterGATDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for multi-modal promoter prediction.\"\"\"\n",
    "    def __init__(self, sequences, gene_ids_master_for_dataset, labels, biological_priors_for_dataset, final_gene_order_in_gat_data):\n",
    "        n_seq = len(sequences)\n",
    "        if not (n_seq == len(gene_ids_master_for_dataset) == len(labels) == len(biological_priors_for_dataset)):\n",
    "            raise ValueError(f\"Dataset input length mismatch: seq={n_seq}, ids={len(gene_ids_master_for_dataset)}, labels={len(labels)}, priors={len(biological_priors_for_dataset)}\")\n",
    "\n",
    "        self.sequences = torch.tensor(sequences, dtype=torch.int64)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)\n",
    "        self.priors = torch.tensor(biological_priors_for_dataset, dtype=torch.float32)\n",
    "        self.gat_gene_to_idx_map = {gene: idx for idx, gene in enumerate(final_gene_order_in_gat_data)}\n",
    "        self.sample_id_to_aligned_gat_idx = np.array([self.gat_gene_to_idx_map.get(gid, -1) for gid in gene_ids_master_for_dataset], dtype=np.int64)\n",
    "        num_missing = (self.sample_id_to_aligned_gat_idx == -1).sum()\n",
    "        if num_missing > 0: log_message(f\"Dataset Warning: {num_missing}/{len(gene_ids_master_for_dataset)} sample gene IDs not in final GAT gene order. Will have aligned_gat_idx = -1.\")\n",
    "\n",
    "    def __len__(self): return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        return {'sequence': self.sequences[idx], 'priors': self.priors[idx], 'label': self.labels[idx], 'aligned_gat_idx': self.sample_id_to_aligned_gat_idx[idx]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe62c80-de37-4348-b66d-1e40c2ed0e8f",
   "metadata": {},
   "source": [
    "## **6. Model Architecture Classes**\n",
    "\n",
    "This section defines the PyTorch modules for the multi-modal architecture.\n",
    "*   **`GATLayer` & `GATNetwork`**: Implement the graph attention mechanism for processing tissue-specific gene-gene networks (derived from TF co-regulation) and aggregating information across tissues.\n",
    "*   **`TransformerBranch`**: Processes DNA sequences using embeddings, positional encoding, and multi-head self-attention.\n",
    "*   **`BWAFusionLayer` (Novel Component)**: The core of the proposed fusion strategy. It uses the biological prior features to learn attention weights ($\\alpha_{\\text{seq}}, \\alpha_{\\text{graph}}$). These weights then modulate the outputs of the Transformer and GAT branches. The modulated features are summed and then concatenated with the original priors before passing to a final classifier. This allows prior knowledge to dynamically influence the contribution of sequence versus network information.\n",
    "*   **`FullModel`**: Integrates all branches and the BWAF layer. It includes a method to precompute the GAT branch output for training efficiency.\n",
    "\n",
    "### Mathematical Formulation of BWAF\n",
    "Given sequence features $h_{\\text{seq}} \\in \\mathbb{R}^{d_{\\text{embed}}}$, graph features $h_{\\text{graph}} \\in \\mathbb{R}^{d_{\\text{embed}}}$, and prior features $h_{\\text{prior}} \\in \\mathbb{R}^{d_{\\text{priors}}}$ for a sample:\n",
    "1.  Attention weights from priors:\n",
    "    \\[ \\alpha_{\\text{seq}} = \\sigma(W_{s} h_{\\text{prior}} + b_{s}) \\quad ; \\quad \\alpha_{\\text{graph}} = \\sigma(W_{g} h_{\\text{prior}} + b_{g}) \\]\n",
    "2.  Modulate features: \\(h_{\\text{seq\\_w}} = \\alpha_{\\text{seq}} \\odot h_{\\text{seq}}\\) ; \\(h_{\\text{graph\\_w}} = \\alpha_{\\text{graph}} \\odot h_{\\text{graph}}\\)\n",
    "3.  Combine modulated: \\(h_{\\text{fused\\_wgtd}} = h_{\\text{seq\\_w}} + h_{\\text{graph\\_w}}\\)\n",
    "4.  Final integration: \\(h_{\\text{final}} = \\text{concat}(h_{\\text{fused\\_wgtd}}, h_{\\text{prior}})\\)\n",
    "5.  Prediction: \\(\\text{logits} = \\text{Classifier}(\\text{LayerNorm}(h_{\\text{final}}))\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f6ee1ca-1d4b-4205-8470-02a05f0fd359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 6. Model Architecture Classes\n",
    "# ============================================================================\n",
    "\n",
    "class GATLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Wrapper for PyTorch Geometric's GATConv layer.\n",
    "    This layer performs graph attention on node features based on the graph structure.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input features per node.\n",
    "        out_channels (int): Number of output features per node (per head).\n",
    "        heads (int): Number of attention heads.\n",
    "        dropout (float): Dropout rate for attention coefficients.\n",
    "        concat (bool): If True, head outputs are concatenated; otherwise, averaged.\n",
    "        activation_fn (callable, optional): Activation function to apply after GAT convolution.\n",
    "                                           PyG's GATConv uses LeakyReLU internally if its own `act` is not specified.\n",
    "        add_self_loops (bool): If True, adds self-loops to the adjacency matrix.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, heads=1, dropout=0.6,\n",
    "                 concat=True, activation_fn=F.elu, add_self_loops=True):\n",
    "        super().__init__()\n",
    "        self.activation_fn = activation_fn\n",
    "        # GATConv has built-in LeakyReLU (negative_slope=0.2) if activation is None\n",
    "        # If we want a different activation, we pass it here. If None, GATConv uses LeakyReLU.\n",
    "        # For clarity, if we always want ELU (or another specific one post-conv), we can apply it externally.\n",
    "        self.gat_conv = GATConv(in_channels, out_channels, heads=heads, dropout=dropout,\n",
    "                                concat=concat, add_self_loops=add_self_loops,\n",
    "                                negative_slope=0.2) # Default for LeakyReLU used in GAT paper\n",
    "        self.concat = concat\n",
    "        self.out_channels_per_head = out_channels\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        x: Node features (Num_Nodes, In_Channels)\n",
    "        edge_index: Graph connectivity (2, Num_Edges)\n",
    "        \"\"\"\n",
    "        h = self.gat_conv(x, edge_index)\n",
    "        # Apply activation *after* the convolution if specified and different from GATConv's internal\n",
    "        if self.activation_fn:\n",
    "             h = self.activation_fn(h)\n",
    "        return h\n",
    "\n",
    "    def get_output_dim(self):\n",
    "        \"\"\"Returns the output dimension of this layer.\"\"\"\n",
    "        if self.concat:\n",
    "            return self.out_channels_per_head * self.gat_conv.heads\n",
    "        else: # Heads are averaged by GATConv if concat=False\n",
    "            return self.out_channels_per_head\n",
    "\n",
    "class GATNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Processes multiple tissue-specific gene graphs using GAT layers.\n",
    "    Applies GAT layers independently for each tissue and then aggregates\n",
    "    the resulting gene embeddings (e.g., by averaging).\n",
    "\n",
    "    Args:\n",
    "        num_genes_nodes (int): Total number of unique genes (nodes) in the graphs.\n",
    "        initial_node_feature_dim (int): Dimensionality of the input features for each gene (e.g., N_TFs).\n",
    "        num_tissues_to_process (int): The number of tissue-specific graphs/edge_indices expected.\n",
    "        hidden_dim (int): Target output dimension of the GAT branch features (per gene) after aggregation.\n",
    "        num_layers (int): Number of GAT layers to stack per tissue.\n",
    "        heads (int): Number of attention heads for intermediate GAT layers.\n",
    "        final_heads (int): Number of attention heads for the final GAT layer.\n",
    "        dropout (float): Dropout rate.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_genes_nodes, initial_node_feature_dim, num_tissues_to_process,\n",
    "                 hidden_dim, num_layers=NUM_GAT_LAYERS, heads=GAT_HEADS,\n",
    "                 final_heads=GAT_FINAL_HEADS, dropout=DROPOUT_RATE):\n",
    "        super().__init__()\n",
    "        if num_layers < 1: raise ValueError(\"Number of GAT layers must be at least 1.\")\n",
    "\n",
    "        self.num_tissues_to_process = num_tissues_to_process\n",
    "        self.num_layers = num_layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropout_layer = nn.Dropout(p=dropout)\n",
    "\n",
    "        in_channels = initial_node_feature_dim\n",
    "        for i in range(self.num_layers):\n",
    "            is_final_layer = (i == self.num_layers - 1)\n",
    "            current_heads = heads if not is_final_layer else final_heads\n",
    "            # Intermediate layers concat, final layer averages to get hidden_dim\n",
    "            concat_heads = not is_final_layer\n",
    "            # Output channels per head. If final layer averages, it directly outputs hidden_dim.\n",
    "            # If intermediate layer concats, each head outputs hidden_dim / current_heads.\n",
    "            out_ch_per_head = hidden_dim\n",
    "            if concat_heads:\n",
    "                if hidden_dim % current_heads != 0:\n",
    "                    raise ValueError(f\"GATNetwork: hidden_dim ({hidden_dim}) must be divisible by \"\n",
    "                                     f\"intermediate heads ({current_heads}) if concat=True.\")\n",
    "                out_ch_per_head = hidden_dim // current_heads\n",
    "\n",
    "            # Apply activation for all layers except the very last one (its output is aggregated)\n",
    "            # GATConv already has LeakyReLU, so external activation is only if we want something else.\n",
    "            # Usually, ELU or ReLU is applied *after* GATConv output.\n",
    "            layer_activation = F.elu if not is_final_layer else None # No explicit activation on last GAT layer output before aggregation\n",
    "\n",
    "            gat_layer = GATLayer(in_channels, out_ch_per_head, heads=current_heads,\n",
    "                                 dropout=dropout, concat=concat_heads,\n",
    "                                 activation_fn=layer_activation, add_self_loops=True)\n",
    "            self.layers.append(gat_layer)\n",
    "            in_channels = gat_layer.get_output_dim() # This will be hidden_dim if final, or hidden_dim if intermediate concat\n",
    "\n",
    "        self.final_output_dim = in_channels # This should be hidden_dim after the GAT stack\n",
    "\n",
    "    def forward(self, x_node, edge_indices_list):\n",
    "        \"\"\"\n",
    "        Applies GAT layers per tissue and aggregates the final gene embeddings.\n",
    "        x_node: Initial node features (Num_Genes_Aligned, Initial_Node_Feature_Dim).\n",
    "        edge_indices_list: List of edge_index tensors for each tissue.\n",
    "        \"\"\"\n",
    "        num_available_edge_indices = len(edge_indices_list)\n",
    "        if num_available_edge_indices == 0 and self.num_tissues_to_process > 0:\n",
    "            log_message(\"GATNetwork FWD Error: No edge indices provided but tissues expected. Returning zeros.\")\n",
    "            return torch.zeros(x_node.shape[0], self.final_output_dim, device=x_node.device)\n",
    "\n",
    "        # Determine how many tissues will actually be processed\n",
    "        actual_tissues_to_loop_over = min(num_available_edge_indices, self.num_tissues_to_process)\n",
    "        if actual_tissues_to_loop_over != self.num_tissues_to_process:\n",
    "             log_message(f\"GATNetwork FWD Warning: Processing {actual_tissues_to_loop_over} tissues \"\n",
    "                         f\"(based on {num_available_edge_indices} available edge_indices), \"\n",
    "                         f\"though GATNetwork configured for {self.num_tissues_to_process} tissues.\")\n",
    "\n",
    "        tissue_final_layer_outputs = []\n",
    "        for i in range(actual_tissues_to_loop_over):\n",
    "            h = x_node # Start with the same initial features for each tissue-specific pass\n",
    "            edge_index = edge_indices_list[i]\n",
    "\n",
    "            if edge_index is None or edge_index.numel() == 0 :\n",
    "                 log_message(f\"GATNetwork FWD: Skipping tissue index {i} due to missing or empty edge_index.\")\n",
    "                 tissue_final_layer_outputs.append(torch.zeros(x_node.shape[0], self.final_output_dim, device=x_node.device))\n",
    "                 continue\n",
    "            if x_node.shape[0] > 0 and edge_index.max().item() >= x_node.shape[0]: # Check edge indices bounds\n",
    "                log_message(f\"GATNetwork FWD ERROR: Max edge_idx {edge_index.max().item()} >= num_nodes {x_node.shape[0]} \"\n",
    "                            f\"for tissue index {i}. Using zeros for this tissue output.\")\n",
    "                tissue_final_layer_outputs.append(torch.zeros(x_node.shape[0], self.final_output_dim, device=x_node.device))\n",
    "                continue\n",
    "\n",
    "            for k_layer_idx, layer_module in enumerate(self.layers):\n",
    "                 h = layer_module(h, edge_index)\n",
    "                 # Apply dropout *after* activation and *before* next GAT layer (for intermediate layers)\n",
    "                 if k_layer_idx < self.num_layers - 1 : # Check against self.num_layers\n",
    "                      if layer_module.activation_fn is not None: # Only apply dropout if there was an activation\n",
    "                           h = self.dropout_layer(h)\n",
    "            tissue_final_layer_outputs.append(h)\n",
    "\n",
    "        if not tissue_final_layer_outputs: # If all tissues were skipped\n",
    "            log_message(\"GATNetwork FWD Error: No valid GAT outputs generated across any tissue.\")\n",
    "            return torch.zeros(x_node.shape[0], self.final_output_dim, device=x_node.device)\n",
    "\n",
    "        stacked_embeddings = torch.stack(tissue_final_layer_outputs, dim=0)\n",
    "        aggregated_embedding = torch.mean(stacked_embeddings, dim=0)\n",
    "        return aggregated_embedding\n",
    "\n",
    "\n",
    "class TransformerBranch(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer branch for sequence processing using nn.TransformerEncoder.\n",
    "    Includes embedding, learnable positional encoding, multi-head self-attention,\n",
    "    masked aggregation, and a final preparation layer for fusion.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size=VOCAB_SIZE, seq_len=SEQ_LEN, embed_dim=EMBEDDING_DIM,\n",
    "                 num_heads=NUM_ATTN_HEADS, ff_dim=TRANSFORMER_FF_DIM,\n",
    "                 num_layers=NUM_TRANSFORMER_LAYERS, dropout=DROPOUT_RATE):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD_IDX)\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, seq_len, embed_dim), requires_grad=True)\n",
    "        self.embed_dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_dim,\n",
    "            dropout=dropout, activation='relu', batch_first=True, norm_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.fusion_prep_layer = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Linear(embed_dim, embed_dim), # Output dimension is embed_dim\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_data):\n",
    "        \"\"\"Forward pass for the Transformer branch.\"\"\"\n",
    "        N, L_actual = seq_data.shape\n",
    "        x = self.embedding(seq_data) # (N, L_actual, E)\n",
    "        pos_enc = self.positional_encoding[:, :L_actual, :] # (1, L_actual, E)\n",
    "        x = x + pos_enc\n",
    "        x = self.embed_dropout(x)\n",
    "\n",
    "        padding_mask = (seq_data == PAD_IDX) # (N, L_actual)\n",
    "        transformer_output = self.transformer_encoder(x, src_key_padding_mask=padding_mask) # (N, L_actual, E)\n",
    "\n",
    "        mask = (~padding_mask).unsqueeze(-1).float() # (N, L_actual, 1)\n",
    "        summed_output = (transformer_output * mask).sum(dim=1) # (N, E)\n",
    "        num_non_padding = mask.sum(dim=1).clamp(min=1.0) # (N, 1), prevent div by zero\n",
    "        aggregated_output = summed_output / num_non_padding # (N, E)\n",
    "\n",
    "        seq_features = self.fusion_prep_layer(aggregated_output) # (N, E)\n",
    "        return seq_features\n",
    "\n",
    "\n",
    "class BWAFusionLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements Biologically Weighted Attention Fusion (BWAF).\n",
    "    Uses biological priors (h_prior) to generate attention weights (alpha_seq, alpha_graph)\n",
    "    that dynamically modulate sequence and graph features before fusion.\n",
    "    \"\"\"\n",
    "    def __init__(self, seq_dim, graph_dim, prior_dim, common_feature_dim,\n",
    "                 fusion_hidden_dim=FUSION_HIDDEN_DIM, dropout=DROPOUT_RATE):\n",
    "        super().__init__()\n",
    "        self.prior_dim = prior_dim # Store prior_dim\n",
    "        self.common_feature_dim = common_feature_dim\n",
    "\n",
    "        # Projection layers to make seq_dim and graph_dim equal to common_feature_dim\n",
    "        self.project_seq = nn.Linear(seq_dim, self.common_feature_dim) if seq_dim != self.common_feature_dim else nn.Identity()\n",
    "        self.project_graph = nn.Linear(graph_dim, self.common_feature_dim) if graph_dim != self.common_feature_dim else nn.Identity()\n",
    "\n",
    "        # Attention Weight Generation\n",
    "        attn_gen_input_dim = max(1, prior_dim) # Handle prior_dim = 0 for Linear layer\n",
    "        attn_gen_hidden = max(16, attn_gen_input_dim // 2) if attn_gen_input_dim > 0 else 16\n",
    "\n",
    "        self.weight_generator_seq = nn.Sequential(\n",
    "            nn.Linear(attn_gen_input_dim, attn_gen_hidden), nn.ReLU(), nn.Linear(attn_gen_hidden, 1)\n",
    "        )\n",
    "        self.weight_generator_graph = nn.Sequential(\n",
    "            nn.Linear(attn_gen_input_dim, attn_gen_hidden), nn.ReLU(), nn.Linear(attn_gen_hidden, 1)\n",
    "        )\n",
    "\n",
    "        # Classifier Part\n",
    "        # Input dimension = common_feature_dim (from weighted sum) + prior_dim (original priors concatenated)\n",
    "        final_combined_dim = self.common_feature_dim + prior_dim # Use original prior_dim for cat size\n",
    "        self.layer_norm = nn.LayerNorm(final_combined_dim)\n",
    "\n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Linear(final_combined_dim, fusion_hidden_dim), nn.ReLU(), nn.Dropout(p=dropout),\n",
    "            nn.Linear(fusion_hidden_dim, fusion_hidden_dim // 2), nn.ReLU(), nn.Dropout(p=dropout),\n",
    "            nn.Linear(fusion_hidden_dim // 2, 1) # Output raw logits\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_features, graph_features, prior_features):\n",
    "        # Handle case where prior_features might be empty if prior_dim is 0\n",
    "        if self.prior_dim > 0:\n",
    "            alpha_seq = torch.sigmoid(self.weight_generator_seq(prior_features))\n",
    "            alpha_graph = torch.sigmoid(self.weight_generator_graph(prior_features))\n",
    "        else: # Fallback if no prior features (prior_dim = 0)\n",
    "            # Create tensors of ones with the correct batch size and device\n",
    "            batch_s = seq_features.size(0)\n",
    "            alpha_seq = torch.ones(batch_s, 1, device=seq_features.device) * 0.5\n",
    "            alpha_graph = torch.ones(batch_s, 1, device=graph_features.device) * 0.5\n",
    "\n",
    "        seq_proj = self.project_seq(seq_features)\n",
    "        graph_proj = self.project_graph(graph_features)\n",
    "\n",
    "        seq_weighted = alpha_seq * seq_proj\n",
    "        graph_weighted = alpha_graph * graph_proj\n",
    "        weighted_fused = seq_weighted + graph_weighted # Element-wise sum\n",
    "\n",
    "        # Ensure prior_features is 2D for concatenation even if prior_dim is 0\n",
    "        priors_to_concat = prior_features if self.prior_dim > 0 else torch.empty(weighted_fused.size(0), 0, device=weighted_fused.device)\n",
    "\n",
    "        final_input = torch.cat([weighted_fused, priors_to_concat], dim=1)\n",
    "\n",
    "        # Apply LayerNorm before the fully connected block\n",
    "        return self.fc_block(self.layer_norm(final_input))\n",
    "\n",
    "\n",
    "class FullModel(nn.Module):\n",
    "    \"\"\"Integrates Transformer, GAT, and BWAFusionLayer.\"\"\"\n",
    "    def __init__(self, num_genes_nodes, initial_node_feature_dim, num_tissues_to_process, prior_dim,\n",
    "                 embed_dim=EMBEDDING_DIM, num_attn_heads=NUM_ATTN_HEADS,\n",
    "                 transformer_ff_dim=TRANSFORMER_FF_DIM, num_transformer_layers=NUM_TRANSFORMER_LAYERS,\n",
    "                 gat_hidden_dim=EMBEDDING_DIM, num_gat_layers=NUM_GAT_LAYERS,\n",
    "                 gat_heads=GAT_HEADS, gat_final_heads=GAT_FINAL_HEADS,\n",
    "                 fusion_hidden_dim=FUSION_HIDDEN_DIM, dropout=DROPOUT_RATE):\n",
    "        super().__init__()\n",
    "        self.transformer = TransformerBranch(\n",
    "            vocab_size=VOCAB_SIZE, seq_len=SEQ_LEN, embed_dim=embed_dim, num_heads=num_attn_heads,\n",
    "            ff_dim=transformer_ff_dim, num_layers=num_transformer_layers, dropout=dropout\n",
    "        )\n",
    "        self.gat = GATNetwork(\n",
    "            num_genes_nodes=num_genes_nodes,\n",
    "            initial_node_feature_dim=initial_node_feature_dim,\n",
    "            num_tissues_to_process=num_tissues_to_process,\n",
    "            hidden_dim=gat_hidden_dim, # GAT output dim before aggregation\n",
    "            num_layers=num_gat_layers,\n",
    "            heads=gat_heads,\n",
    "            final_heads=gat_final_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        gat_output_dim = self.gat.final_output_dim # Actual output dim from GAT branch\n",
    "\n",
    "        self.fusion = BWAFusionLayer(\n",
    "            seq_dim=embed_dim,          # Output dim of Transformer branch\n",
    "            graph_dim=gat_output_dim,   # Output dim of GAT branch\n",
    "            prior_dim=prior_dim,        # Dimension of prior features\n",
    "            common_feature_dim=embed_dim, # Target dim for weighted sum in BWAF\n",
    "            fusion_hidden_dim=fusion_hidden_dim,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.precomputed_gat_output = None\n",
    "        self.gat_device = 'cpu' # Device where GAT output was precomputed\n",
    "\n",
    "    def precompute_gat(self, x_node_static, edge_indices_list_static, device):\n",
    "        \"\"\"Computes and stores the GAT branch output on CPU for efficiency.\"\"\"\n",
    "        log_message(\"Precomputing GAT branch output...\")\n",
    "        start_time = time.time()\n",
    "        self.gat.eval() # Set GAT to evaluation mode for precomputation\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                x_node_static_dev = x_node_static.to(device)\n",
    "                # Ensure edge indices are moved, handle None gracefully\n",
    "                edge_indices_list_static_dev = [\n",
    "                    ei.to(device) if ei is not None and ei.numel() > 0 else None\n",
    "                    for ei in edge_indices_list_static\n",
    "                ]\n",
    "                # Pass only non-None, non-empty edge indices to GAT forward\n",
    "                valid_edge_indices = [ei for ei in edge_indices_list_static_dev if ei is not None]\n",
    "\n",
    "                if not valid_edge_indices:\n",
    "                    log_message(\"ERROR during GAT precomputation: No valid edge indices found after filtering! GAT output will be None.\")\n",
    "                    self.precomputed_gat_output = None\n",
    "                    # Potentially create a zero tensor of expected shape to avoid downstream errors if critical\n",
    "                    # num_nodes = x_node_static.shape[0]\n",
    "                    # self.precomputed_gat_output = torch.zeros(num_nodes, self.gat.final_output_dim, device='cpu')\n",
    "                    return # Exit if no valid edges to process\n",
    "\n",
    "                # If GATNetwork's num_tissues_to_process is strict, this could be an issue\n",
    "                if len(valid_edge_indices) != self.gat.num_tissues_to_process:\n",
    "                     log_message(f\"Warning during GAT precomputation: Processing with {len(valid_edge_indices)} \"\n",
    "                                 f\"valid edge indices. GATNetwork configured for {self.gat.num_tissues_to_process} tissues.\")\n",
    "\n",
    "                self.precomputed_gat_output = self.gat(x_node_static_dev, valid_edge_indices).cpu() # Store on CPU\n",
    "                self.gat_device = device # Remember the device it ran on\n",
    "        except Exception as e:\n",
    "            log_message(f\"Error during GAT precomputation: {e}\")\n",
    "            self.precomputed_gat_output = None; # Reset on error\n",
    "            import traceback; log_message(traceback.format_exc())\n",
    "            # raise # Optionally re-raise to halt execution\n",
    "        finally:\n",
    "            self.gat.train() # Set GAT back to train mode\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        if self.precomputed_gat_output is not None:\n",
    "            log_message(f\"GAT output precomputed on {device}. Shape: {self.precomputed_gat_output.shape}. Time: {elapsed:.2f}s.\")\n",
    "        else:\n",
    "            log_message(f\"GAT precomputation failed or resulted in no output after {elapsed:.2f}s.\")\n",
    "\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"Forward pass implementing the BWAF architecture.\"\"\"\n",
    "        current_device = batch['sequence'].device # Assume batch data is already on the correct device\n",
    "\n",
    "        # 1. Transformer Branch\n",
    "        seq_features = self.transformer(batch['sequence']) # (N, embed_dim)\n",
    "\n",
    "        # 2. GAT Branch Output (Retrieve Precomputed)\n",
    "        if self.precomputed_gat_output is None:\n",
    "             # Fallback: return zeros if GAT output is not available, log critical warning\n",
    "             log_message(\"CRITICAL RUNTIME ERROR: GAT output is None in forward pass. Using zeros for graph features.\")\n",
    "             batch_graph_features = torch.zeros(seq_features.size(0), self.gat.final_output_dim, device=current_device)\n",
    "        else:\n",
    "            # Move precomputed output to the current batch's device\n",
    "            h_graph_agg_all_genes = self.precomputed_gat_output.to(current_device) # (N_genes_aligned, gat_output_dim)\n",
    "\n",
    "            # 3. Select GAT features for the current batch using aligned indices\n",
    "            aligned_gat_indices = batch['aligned_gat_idx'] # (N,) tensor of indices or -1\n",
    "\n",
    "            # Ensure aligned_gat_indices is a tensor and on the correct device for indexing\n",
    "            if not isinstance(aligned_gat_indices, torch.Tensor):\n",
    "                aligned_gat_indices_tensor = torch.tensor(aligned_gat_indices, device=h_graph_agg_all_genes.device, dtype=torch.long)\n",
    "            else:\n",
    "                aligned_gat_indices_tensor = aligned_gat_indices.to(device=h_graph_agg_all_genes.device, dtype=torch.long)\n",
    "\n",
    "            valid_indices_mask = (aligned_gat_indices_tensor != -1) # Boolean mask\n",
    "            valid_gat_indices_for_indexing = aligned_gat_indices_tensor[valid_indices_mask] # Actual indices to use\n",
    "\n",
    "            batch_graph_features = torch.zeros(seq_features.size(0), self.gat.final_output_dim, device=current_device)\n",
    "\n",
    "            if valid_gat_indices_for_indexing.numel() > 0: # If there are any valid genes for this batch\n",
    "                if h_graph_agg_all_genes.shape[0] == 0:\n",
    "                     log_message(f\"RUNTIME WARNING: Precomputed GAT output (h_graph_agg_all_genes) is empty. Graph features will be zero.\")\n",
    "                # Check bounds before indexing\n",
    "                elif valid_gat_indices_for_indexing.max().item() >= h_graph_agg_all_genes.shape[0]:\n",
    "                     log_message(f\"RUNTIME ERROR: Max index {valid_gat_indices_for_indexing.max().item()} for GAT features out of bounds ({h_graph_agg_all_genes.shape[0]})\")\n",
    "                     # Zeros will be used as batch_graph_features was initialized with zeros\n",
    "                else:\n",
    "                     selected_graph_features = h_graph_agg_all_genes.index_select(0, valid_gat_indices_for_indexing)\n",
    "                     # Use the boolean mask (on the current_device) to place the selected features\n",
    "                     batch_graph_features[valid_indices_mask.to(current_device)] = selected_graph_features\n",
    "            # If valid_gat_indices_for_indexing.numel() == 0, batch_graph_features remains zeros\n",
    "\n",
    "        # 4. BWAF Fusion Layer\n",
    "        prior_features = batch['priors'] # (N, prior_dim)\n",
    "        logits = self.fusion(seq_features, batch_graph_features, prior_features) # (N, 1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c336de-72b8-4d52-b497-6e23d215f353",
   "metadata": {},
   "source": [
    "## **7. Training Function**\n",
    "\n",
    "This function (`train_model`) handles the model training loop, including forward/backward passes, optimization, validation, learning rate scheduling, model saving, and loss plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b68a832d-2e4e-494d-8b67-3b8a1f203e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 7. Training Function\n",
    "# ============================================================================\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device,\n",
    "                model_save_path=MODEL_SAVE_PATH, loss_plot_path=LOSS_PLOT_PATH, scheduler=None):\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    if model.precomputed_gat_output is None and hasattr(model, 'precompute_gat'):\n",
    "         log_message(\"CRITICAL ERROR: GAT output must be precomputed for training.\"); return None\n",
    "\n",
    "    log_message(f\"--- Starting Training for {num_epochs} Epochs ---\")\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time(); model.train(); running_train_loss = 0.0\n",
    "        train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", leave=False)\n",
    "        for batch in train_loop:\n",
    "            batch_on_device = {k: v.to(device) if isinstance(v,torch.Tensor) else v for k,v in batch.items()}\n",
    "            labels = batch_on_device['label']\n",
    "            optimizer.zero_grad(); logits = model(batch_on_device); loss = criterion(logits, labels)\n",
    "            loss.backward(); optimizer.step(); running_train_loss += loss.item()\n",
    "            train_loop.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        epoch_train_loss = running_train_loss/len(train_loader) if len(train_loader)>0 else 0.0\n",
    "        train_losses.append(epoch_train_loss)\n",
    "\n",
    "        model.eval(); running_val_loss = 0.0\n",
    "        val_loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loop:\n",
    "                batch_on_device = {k: v.to(device) if isinstance(v,torch.Tensor) else v for k,v in batch.items()}\n",
    "                labels = batch_on_device['label']\n",
    "                logits = model(batch_on_device); loss = criterion(logits, labels)\n",
    "                running_val_loss += loss.item(); val_loop.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "        epoch_val_loss = running_val_loss/len(val_loader) if len(val_loader)>0 else 0.0\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        if scheduler: scheduler.step(epoch_val_loss)\n",
    "\n",
    "        log_message(f\"E {epoch+1}/{num_epochs} - TrL: {epoch_train_loss:.4f}, VaL: {epoch_val_loss:.4f}, Dur: {time.time()-start_time:.2f}s, LR: {current_lr:.2e}\")\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss; torch.save(model.state_dict(), model_save_path)\n",
    "            log_message(f\"Saved best model (Val Loss: {best_val_loss:.4f})\")\n",
    "\n",
    "    try: # Plotting\n",
    "        plt.figure(figsize=(10,6)); epochs_range = range(1,num_epochs+1) if num_epochs > 0 else [1]\n",
    "        plt.plot(epochs_range,train_losses,label='Train Loss',marker='.'); plt.plot(epochs_range,val_losses,label='Val Loss',marker='.')\n",
    "        plt.xlabel('Epochs'); plt.ylabel('Loss'); plt.title('Training & Validation Loss'); plt.legend(); plt.grid(True,linestyle=':'); plt.tight_layout(); plt.savefig(loss_plot_path, dpi=300); plt.close()\n",
    "        log_message(f\"Saved loss plot to {loss_plot_path}\")\n",
    "    except Exception as e: log_message(f\"Error plotting loss: {e}\")\n",
    "    log_message(f\"--- Training Finished --- Best Val Loss: {best_val_loss:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04628410-19e8-43ee-9407-c1d83e9b73b3",
   "metadata": {},
   "source": [
    "## **8. Evaluation Function**\n",
    "\n",
    "This section defines functions for model evaluation on the test set:\n",
    "*   `plot_confusion_matrix`: Generates and saves a heatmap visualization of the confusion matrix.\n",
    "*   `evaluate_model`: Performs inference on the test set, calculates classification metrics (Accuracy, Precision, Recall, F1, Specificity, AUC-ROC, TP/FP/TN/FN), logs results, plots the confusion matrix, and saves metrics to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aefe52b-8776-4f0b-a7cd-9571d7c72c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 8. Evaluation Function\n",
    "# ============================================================================\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues, save_path=CONFUSION_MATRIX_PATH):\n",
    "    \"\"\"Plots and saves the confusion matrix.\"\"\"\n",
    "    try:\n",
    "        if normalize:\n",
    "            cm_sum = cm.sum(axis=1)[:, np.newaxis]\n",
    "            cm_plot = np.divide(cm.astype('float'), cm_sum, out=np.zeros_like(cm,dtype=float), where=cm_sum!=0)\n",
    "            fmt = '.2f'; plot_title = title + ' (Normalized)'\n",
    "        else:\n",
    "            fmt = 'd'; cm_plot = cm; plot_title = title\n",
    "        plt.figure(figsize=(8,6)); sns.heatmap(cm_plot, annot=True, fmt=fmt, cmap=cmap, xticklabels=classes, yticklabels=classes, square=True, cbar=False, linewidths=.5, linecolor='grey', annot_kws={\"size\":10}); plt.title(plot_title, fontsize=14); plt.ylabel('True label', fontsize=12); plt.xlabel('Predicted label', fontsize=12); plt.xticks(fontsize=10); plt.yticks(fontsize=10,rotation=0); plt.tight_layout(); plt.savefig(save_path, dpi=300); plt.close()\n",
    "        log_message(f\"Saved CM to {save_path}\")\n",
    "    except Exception as e: log_message(f\"Error plotting CM: {e}\")\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device, results_csv_path=RESULTS_CSV_PATH):\n",
    "    \"\"\"Evaluates model, logs metrics, plots CM, saves results.\"\"\"\n",
    "    model.eval(); all_labels, all_preds, all_probs = [], [], []; running_test_loss = 0.0\n",
    "    if model.precomputed_gat_output is None and hasattr(model, 'precompute_gat'): log_message(\"CRITICAL: GAT output not precomputed for eval.\"); return None\n",
    "\n",
    "    log_message(f\"--- Evaluating on test set ({len(test_loader)} batches) ---\")\n",
    "    test_loop = tqdm(test_loader, desc=\"Evaluating [Test]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loop:\n",
    "            batch_on_device = {k: v.to(device) if isinstance(v,torch.Tensor) else v for k,v in batch.items()}\n",
    "            labels = batch_on_device['label']\n",
    "            logits = model(batch_on_device); loss = criterion(logits, labels)\n",
    "            running_test_loss += loss.item()\n",
    "            probs = torch.sigmoid(logits); preds = (probs > 0.5).float()\n",
    "            all_labels.extend(labels.cpu().numpy()); all_preds.extend(preds.cpu().numpy()); all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    test_loss = running_test_loss/len(test_loader) if len(test_loader)>0 else 0.0\n",
    "    all_labels=np.array(all_labels).flatten(); all_preds=np.array(all_preds).flatten(); all_probs=np.array(all_probs).flatten()\n",
    "    \n",
    "    accuracy=accuracy_score(all_labels,all_preds); precision=precision_score(all_labels,all_preds,zero_division=0)\n",
    "    recall=recall_score(all_labels,all_preds,zero_division=0); f1=f1_score(all_labels,all_preds,zero_division=0)\n",
    "    \n",
    "    # Robust confusion matrix calculation\n",
    "    unique_test_labels = np.unique(all_labels)\n",
    "    cm_sklearn_labels = [0,1] if len(unique_test_labels) == 2 else unique_test_labels.tolist() if len(unique_test_labels) == 1 else [0,1] # Default to [0,1] if empty or unexpected\n",
    "    if not cm_sklearn_labels: cm_sklearn_labels = [0,1] # Final fallback\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=cm_sklearn_labels)\n",
    "\n",
    "    if cm.shape == (2,2): tn,fp,fn,tp = cm.ravel()\n",
    "    elif cm.shape == (1,1) and 0 in cm_sklearn_labels : tn,fp,fn,tp = cm[0,0],0,0,0\n",
    "    elif cm.shape == (1,1) and 1 in cm_sklearn_labels : tn,fp,fn,tp = 0,0,0,cm[0,0]\n",
    "    else: log_message(f\"CM shape {cm.shape}, labels {cm_sklearn_labels} unhandled.\"); tn,fp,fn,tp = 0,0,0,0\n",
    "    \n",
    "    specificity = tn/(tn+fp) if (tn+fp)>0 else 0.0\n",
    "    auc = roc_auc_score(all_labels, all_probs) if len(unique_test_labels)>1 else np.nan\n",
    "    if np.isnan(auc): log_message(f\"AUC is NaN (likely single class in labels/preds for test set).\")\n",
    "\n",
    "    results = {'loss':test_loss, 'acc':accuracy, 'prec':precision, 'rec':recall, 'spec':specificity, 'f1':f1, 'auc':auc, 'TP':int(tp),'FP':int(fp),'TN':int(tn),'FN':int(fn)}\n",
    "    log_message(\"\\n--- Test Set Results ---\")\n",
    "    for k,v in results.items(): log_message(f\"{k.upper()}: {v:.4f}\" if isinstance(v,float) else f\"{k.upper()}: {v}\")\n",
    "    plot_confusion_matrix(cm, ['Non-P','P'], normalize=False, title='Test CM (Counts)')\n",
    "    plot_confusion_matrix(cm, ['Non-P','P'], normalize=True, save_path=CONFUSION_MATRIX_PATH.replace('.png','_norm.png'))\n",
    "    try: pd.DataFrame([results]).to_csv(results_csv_path,index=False); log_message(f\"Saved test results to {results_csv_path}\")\n",
    "    except IOError as e: log_message(f\"Error saving test CSV: {e}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9503a16d-fe96-46a3-bbf9-2ff11663f80d",
   "metadata": {},
   "source": [
    "## **9. Main Execution Block**\n",
    "\n",
    "This block orchestrates the entire pipeline from argument parsing to final evaluation. It ensures data is loaded and preprocessed in the correct order, the model is initialized, GAT outputs are precomputed, training occurs, and the best model is evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85a2b17d-d41d-48fe-90fe-18498fe7936b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-04 18:28:57] --- Starting BWAF Multi-Modal Promoter Prediction Workflow ---\n",
      "[2025-06-04 18:28:57] Interactive environment detected, using default args.\n",
      "[2025-06-04 18:28:57] Runtime Config: Epochs=10, Batch=16, LR=0.0005, Embed=64, Dropout=0.3, GAT ThrFactor=2.5, FusionHidden=128\n",
      "[2025-06-04 18:28:57] \n",
      "--- Step 1: Loading Sequence Data ---\n",
      "[2025-06-04 18:28:57] Loading sequences from data/raw/human_genome_annotation/updated_promoter_features_clean.csv...\n",
      "[2025-06-04 18:28:57] Sequence QC for updated_promoter_features_clean.csv: Total initial: 20028. Removed 0 (with 'N'). Removed 0 (not 2000bp). Final: 20028.\n",
      "[2025-06-04 18:28:57] Loaded and filtered 20028 sequences from updated_promoter_features_clean.csv in 0.79s.\n",
      "[2025-06-04 18:28:57] Loading sequences from data/raw/human_genome_annotation/updated_non_promoter_sequences.csv...\n",
      "[2025-06-04 18:28:58] Sequence QC for updated_non_promoter_sequences.csv: Total initial: 20028. Removed 0 (with 'N'). Removed 0 (not 2000bp). Final: 20028.\n",
      "[2025-06-04 18:28:58] Loaded and filtered 20028 sequences from updated_non_promoter_sequences.csv in 0.73s.\n",
      "[2025-06-04 18:28:58] Total sequences loaded and QC'd: 40056\n",
      "[2025-06-04 18:28:58] Unique master gene IDs for GAT/Prior alignment: 20028\n",
      "[2025-06-04 18:28:58] \n",
      "--- Step 2: Loading and Processing Priors ---\n",
      "[2025-06-04 18:28:58] Loading priors from data/raw/human_genome_annotation/biological_prior_for_transformer_branch.csv...\n",
      "[2025-06-04 18:28:58] Found 11 prior count columns.\n",
      "[2025-06-04 18:28:58] Processed priors for 20028 genes in 0.17s.\n",
      "[2025-06-04 18:28:58] Prior dimension: 11. Priors prepared for 40056 dataset samples.\n",
      "[2025-06-04 18:28:58] \n",
      "--- Step 3: Encoding Sequences ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a1287b51cc43d5a081278879bd990f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding sequences:   0%|          | 0/40056 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-04 18:29:16] \n",
      "--- Step 4: Processing GAT Data ---\n",
      "[2025-06-04 18:29:16] Preprocessing GAT data: data/raw/gene_interaction_network/GRAND_networks -> data/preprocessed/gat_normalized\n",
      "[2025-06-04 18:29:16] Processed GAT files found. Verifying TF/Gene alignment...\n",
      "[2025-06-04 18:29:20] GAT preprocessing complete. Master TFs: 644, Aligned Genes: 20028\n",
      "[2025-06-04 18:29:20] Loading processed GAT data from data/preprocessed/gat_normalized (aligning to 20028 genes, 644 TFs)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8154d36010a4629b90df04e46c1df1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading processed GAT matrices:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-04 18:31:55] Loaded 36 GAT matrices, created initial node features in 154.72s.\n",
      "[2025-06-04 18:31:55] Initial GAT node features (X_node). Shape: torch.Size([20028, 644])\n",
      "[2025-06-04 18:31:55] GAT Edge Indices (TF Co-reg Gene-Gene, ThrFactor: 2.5, MaxEdges: 1000000)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1775164a094547f1bdf8053382944f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating Gene-Gene edge indices:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-04 18:31:56] Finished processing 36 Gene-Gene edge indices.\n",
      "[2025-06-04 18:31:56] \n",
      "--- Step 5: Creating Datasets and DataLoaders ---\n",
      "[2025-06-04 18:31:56] Dataset split: Train=28040, Val=6008, Test=6008\n",
      "[2025-06-04 18:31:56] \n",
      "--- Step 6: Initializing BWAF Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zed/miniconda3/envs/my_env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-04 18:31:56] Model Initialized. Trainable Params: 292,601\n",
      "[2025-06-04 18:31:56] \n",
      "--- Step 7: Precomputing GAT Output ---\n",
      "[2025-06-04 18:31:56] Precomputing GAT branch output...\n",
      "[2025-06-04 18:32:15] GAT output precomputed on cpu. Shape: torch.Size([20028, 64]). Time: 19.13s.\n",
      "[2025-06-04 18:32:15] \n",
      "--- Step 8: Training Model ---\n",
      "[2025-06-04 18:32:15] --- Starting Training for 10 Epochs ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2823925a1a144305aca66f1fbd763237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10 [Train]:   0%|          | 0/1753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9bead255f441f6ab95e01786950eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10 [Val]:   0%|          | 0/376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-05 02:01:46] E 1/10 - TrL: 0.4090, VaL: 0.1203, Dur: 26970.47s, LR: 5.00e-04\n",
      "[2025-06-05 02:01:46] Saved best model (Val Loss: 0.1203)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f5c8a9d0f4443aae1debef189c5089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10 [Train]:   0%|          | 0/1753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c850f5797f98474181f5cd8e24f408c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10 [Val]:   0%|          | 0/376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-05 09:29:27] E 2/10 - TrL: 0.0807, VaL: 0.0301, Dur: 26860.80s, LR: 5.00e-04\n",
      "[2025-06-05 09:29:27] Saved best model (Val Loss: 0.0301)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a15f9b39974843a82aca0c642cefa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10 [Train]:   0%|          | 0/1753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf8fd6dddc8425286ffd266d58e34a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10 [Val]:   0%|          | 0/376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-05 17:03:21] E 3/10 - TrL: 0.0363, VaL: 0.0124, Dur: 27234.67s, LR: 5.00e-04\n",
      "[2025-06-05 17:03:21] Saved best model (Val Loss: 0.0124)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1612881f9a450097c633f8ac02329f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10 [Train]:   0%|          | 0/1753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5eb49ef05745b2b29b7328fa524fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10 [Val]:   0%|          | 0/376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-06 00:29:27] E 4/10 - TrL: 0.0250, VaL: 0.0123, Dur: 26765.42s, LR: 5.00e-04\n",
      "[2025-06-06 00:29:27] Saved best model (Val Loss: 0.0123)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc73b6e8180b45d78bb7dd7892a488b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10 [Train]:   0%|          | 0/1753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a2692ecb2443a096c1fd638bb6352c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10 [Val]:   0%|          | 0/376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-06 07:49:49] E 5/10 - TrL: 0.0205, VaL: 0.0089, Dur: 26422.10s, LR: 5.00e-04\n",
      "[2025-06-06 07:49:49] Saved best model (Val Loss: 0.0089)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6523a730cd114261b6627a95539c8153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10 [Train]:   0%|          | 0/1753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6562a64db044369ddc269025050075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10 [Val]:   0%|          | 0/376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-06 15:15:55] E 6/10 - TrL: 0.0167, VaL: 0.0086, Dur: 26765.95s, LR: 5.00e-04\n",
      "[2025-06-06 15:15:55] Saved best model (Val Loss: 0.0086)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c28f378447a4d59971a036e8919923c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10 [Train]:   0%|          | 0/1753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98ecbb7cdef4b1b8da8118d8673ab00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10 [Val]:   0%|          | 0/376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-06 23:00:55] E 7/10 - TrL: 0.0160, VaL: 0.0109, Dur: 27900.61s, LR: 5.00e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b279c8b04b54e29b5dbae0893dfe88b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10 [Train]:   0%|          | 0/1753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e055cbee2fe946e28a553257738ff455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10 [Val]:   0%|          | 0/376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-07 07:22:37] E 8/10 - TrL: 0.0135, VaL: 0.0060, Dur: 30101.59s, LR: 5.00e-04\n",
      "[2025-06-07 07:22:37] Saved best model (Val Loss: 0.0060)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e147347dce4eba90888c2d831ff0f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10 [Train]:   0%|          | 0/1753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f207eef771244a4cac758aee1c695bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10 [Val]:   0%|          | 0/376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-07 16:06:44] E 9/10 - TrL: 0.0115, VaL: 0.0073, Dur: 31446.88s, LR: 5.00e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa10524d3c8421b9d3e14eea295e56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10 [Train]:   0%|          | 0/1753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee382ab63bb4439d882291723be3649e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10 [Val]:   0%|          | 0/376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-08 00:46:28] E 10/10 - TrL: 0.0112, VaL: 0.0113, Dur: 31183.75s, LR: 5.00e-04\n",
      "[2025-06-08 00:46:28] Saved loss plot to results_bwaf_v3/training_validation_loss_bwaf.png\n",
      "[2025-06-08 00:46:28] --- Training Finished --- Best Val Loss: 0.0060\n",
      "[2025-06-08 00:46:28] \n",
      "--- Step 9: Evaluating Best Model ---\n",
      "[2025-06-08 00:46:28] Loading best model state from 'results_bwaf_v3/best_promoter_model_bwaf.pth' for final evaluation.\n",
      "[2025-06-08 00:46:28] --- Evaluating on test set (376 batches) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "402d5f91d6494af78ad060a24929c57c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating [Test]:   0%|          | 0/376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-08 01:14:48] \n",
      "--- Test Set Results ---\n",
      "[2025-06-08 01:14:48] LOSS: 0.0060\n",
      "[2025-06-08 01:14:48] ACC: 0.9987\n",
      "[2025-06-08 01:14:48] PREC: 1.0000\n",
      "[2025-06-08 01:14:48] REC: 0.9973\n",
      "[2025-06-08 01:14:48] SPEC: 1.0000\n",
      "[2025-06-08 01:14:48] F1: 0.9987\n",
      "[2025-06-08 01:14:48] AUC: 0.9999\n",
      "[2025-06-08 01:14:48] TP: 3010\n",
      "[2025-06-08 01:14:48] FP: 0\n",
      "[2025-06-08 01:14:48] TN: 2990\n",
      "[2025-06-08 01:14:48] FN: 8\n",
      "[2025-06-08 01:14:48] Saved CM to results_bwaf_v3/confusion_matrix_bwaf.png\n",
      "[2025-06-08 01:14:48] Saved CM to results_bwaf_v3/confusion_matrix_bwaf_norm.png\n",
      "[2025-06-08 01:14:48] Saved test results to results_bwaf_v3/test_set_evaluation_results_bwaf.csv\n",
      "[2025-06-08 01:14:48] \n",
      "--- Workflow Completed Successfully in 283551.59 seconds (78.76 hours) ---\n"
     ]
    }
   ],
   "source": [
    "# %% 9. Main Execution Block\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    log_message(\"--- Starting BWAF Multi-Modal Promoter Prediction Workflow ---\")\n",
    "    script_start_time = time.time()\n",
    "\n",
    "    # --- Argument Parsing ---\n",
    "    class Args: \"\"\"Mock class for arguments when not using command-line parsing.\"\"\"\n",
    "    if 'ipykernel' in sys.modules or 'google.colab' in sys.modules:\n",
    "        log_message(\"Interactive environment detected, using default args.\")\n",
    "        args = Args(); args.epochs=NUM_EPOCHS; args.batch_size=BATCH_SIZE; args.lr=LEARNING_RATE; args.embed_dim=EMBEDDING_DIM\n",
    "        args.dropout=DROPOUT_RATE; args.gat_layers=NUM_GAT_LAYERS; args.transformer_layers=NUM_TRANSFORMER_LAYERS\n",
    "        args.gat_threshold_factor=GAT_INTERACTION_THRESHOLD_STD_FACTOR; args.fusion_hidden=FUSION_HIDDEN_DIM\n",
    "        args.force_gat_preprocess=False; args.force_edge_rebuild=False; args.no_cuda=False\n",
    "        # --- Example: Manual override for interactive testing ---\n",
    "        # args.epochs = 2 # For quick test\n",
    "        # args.batch_size = 16\n",
    "        # args.force_edge_rebuild = True # Uncomment to test edge creation\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser(description=\"Train BWAF Multi-Modal Promoter Prediction Model\")\n",
    "        parser.add_argument('--epochs',type=int,default=NUM_EPOCHS, help=f\"Epochs (def: {NUM_EPOCHS})\")\n",
    "        parser.add_argument('--batch_size',type=int,default=BATCH_SIZE, help=f\"Batch size (def: {BATCH_SIZE})\")\n",
    "        parser.add_argument('--lr',type=float,default=LEARNING_RATE, help=f\"Learning rate (def: {LEARNING_RATE})\")\n",
    "        parser.add_argument('--embed_dim',type=int,default=EMBEDDING_DIM, help=f\"Embed/Hidden dim (def: {EMBEDDING_DIM})\")\n",
    "        parser.add_argument('--dropout',type=float,default=DROPOUT_RATE, help=f\"Dropout rate (def: {DROPOUT_RATE})\")\n",
    "        parser.add_argument('--gat_layers',type=int,default=NUM_GAT_LAYERS, help=f\"GAT layers (def: {NUM_GAT_LAYERS})\")\n",
    "        parser.add_argument('--transformer_layers',type=int,default=NUM_TRANSFORMER_LAYERS, help=f\"Transformer layers (def: {NUM_TRANSFORMER_LAYERS})\")\n",
    "        parser.add_argument('--gat_threshold_factor',type=float,default=GAT_INTERACTION_THRESHOLD_STD_FACTOR, help=f\"GAT edge TF co-reg threshold factor (def: {GAT_INTERACTION_THRESHOLD_STD_FACTOR})\")\n",
    "        parser.add_argument('--fusion_hidden',type=int,default=FUSION_HIDDEN_DIM, help=f\"Fusion hidden dim (def: {FUSION_HIDDEN_DIM})\")\n",
    "        parser.add_argument('--force_gat_preprocess',action='store_true', help='Force filtering/normalization of GAT data.')\n",
    "        parser.add_argument('--force_edge_rebuild',action='store_true', help='Force rebuilding GAT edge indices.')\n",
    "        parser.add_argument('--no_cuda',action='store_true', help='Disable CUDA.');\n",
    "        args = parser.parse_args()\n",
    "\n",
    "    # Update Config from Args\n",
    "    NUM_EPOCHS=args.epochs; BATCH_SIZE=args.batch_size; LEARNING_RATE=args.lr; EMBEDDING_DIM=args.embed_dim\n",
    "    DROPOUT_RATE=args.dropout; NUM_GAT_LAYERS=args.gat_layers; NUM_TRANSFORMER_LAYERS=args.transformer_layers\n",
    "    GAT_INTERACTION_THRESHOLD_STD_FACTOR=args.gat_threshold_factor; FUSION_HIDDEN_DIM=args.fusion_hidden\n",
    "    if args.no_cuda: DEVICE=torch.device(\"cpu\"); log_message(\"CUDA disabled by argument.\")\n",
    "    log_message(f\"Runtime Config: Epochs={NUM_EPOCHS}, Batch={BATCH_SIZE}, LR={LEARNING_RATE}, Embed={EMBEDDING_DIM}, Dropout={DROPOUT_RATE}, GAT ThrFactor={GAT_INTERACTION_THRESHOLD_STD_FACTOR}, FusionHidden={FUSION_HIDDEN_DIM}\")\n",
    "\n",
    "    try:\n",
    "        # 1. Load Sequences & Get Master Gene List for Alignment\n",
    "        log_message(\"\\n--- Step 1: Loading Sequence Data ---\")\n",
    "        prom_seqs, prom_ids_raw, prom_labels = load_sequences(PROMOTER_SEQ_FILE, True)\n",
    "        nonprom_seqs, nonprom_ids_raw, nonprom_labels = load_sequences(NON_PROMOTER_SEQ_FILE, False)\n",
    "        if not prom_seqs or not nonprom_seqs: raise ValueError(\"Sequence loading failed.\")\n",
    "        all_sequences_raw = prom_seqs + nonprom_seqs\n",
    "        all_gene_ids_for_samples = prom_ids_raw + nonprom_ids_raw # Order for dataset samples\n",
    "        all_labels = prom_labels + nonprom_labels\n",
    "        log_message(f\"Total sequences loaded and QC'd: {len(all_sequences_raw)}\")\n",
    "        # Master list for aligning GAT/Priors is unique genes from all samples\n",
    "        master_gene_id_list_for_alignment = pd.Series(all_gene_ids_for_samples).drop_duplicates(keep='first').tolist()\n",
    "        log_message(f\"Unique master gene IDs for GAT/Prior alignment: {len(master_gene_id_list_for_alignment)}\")\n",
    "\n",
    "        # 2. Load Priors (aligned to master_gene_id_list_for_alignment)\n",
    "        log_message(\"\\n--- Step 2: Loading and Processing Priors ---\")\n",
    "        priors_features_aligned_to_master_list, prior_dim = load_priors(PRIOR_FILE, master_gene_id_list_for_alignment)\n",
    "        # Now map these aligned priors back to the order of all_gene_ids_for_samples for the Dataset\n",
    "        gene_to_aligned_prior_map = {gene_id: priors_features_aligned_to_master_list[i] for i, gene_id in enumerate(master_gene_id_list_for_alignment)}\n",
    "        final_priors_for_dataset = np.array([gene_to_aligned_prior_map.get(gid, np.zeros(prior_dim, dtype=np.float32)) for gid in all_gene_ids_for_samples])\n",
    "        log_message(f\"Prior dimension: {prior_dim}. Priors prepared for {len(final_priors_for_dataset)} dataset samples.\")\n",
    "\n",
    "        # 3. Encode Sequences\n",
    "        log_message(\"\\n--- Step 3: Encoding Sequences ---\")\n",
    "        all_sequences_encoded = np.array([integer_encode_sequence(seq) for seq in tqdm(all_sequences_raw, desc=\"Encoding sequences\")])\n",
    "\n",
    "        # 4. Process GAT Data\n",
    "        log_message(\"\\n--- Step 4: Processing GAT Data ---\")\n",
    "        num_tfs_master, num_genes_in_aligned_gat_data, final_gene_order_for_gat_cols, master_tf_ids_final = preprocess_all_gat_data(\n",
    "            GAT_RAW_DATA_DIR, GAT_PREPROCESSED_DIR, master_gene_id_list_for_alignment, args.force_gat_preprocess\n",
    "        )\n",
    "        initial_node_features_for_gat, _ = load_processed_gat_data(GAT_PREPROCESSED_DIR, final_gene_order_for_gat_cols, master_tf_ids_final)\n",
    "        log_message(f\"Initial GAT node features (X_node). Shape: {initial_node_features_for_gat.shape}\")\n",
    "\n",
    "        # Determine effective number of tissues based on raw files for edge index creation\n",
    "        _raw_gat_files = glob.glob(os.path.join(GAT_RAW_DATA_DIR, '*.csv'))\n",
    "        effective_num_tissues_for_edges = len(_raw_gat_files) if _raw_gat_files else 0\n",
    "        if effective_num_tissues_for_edges == 0: raise FileNotFoundError(f\"No raw GAT files found in {GAT_RAW_DATA_DIR} for edge index generation.\")\n",
    "        if effective_num_tissues_for_edges != NUM_TISSUES:\n",
    "             log_message(f\"Adjusting NUM_TISSUES for GAT edge/model from {NUM_TISSUES} to {effective_num_tissues_for_edges} based on raw files.\")\n",
    "\n",
    "        edge_indices_list = load_or_create_edge_indices(\n",
    "            num_genes_in_graph=num_genes_in_aligned_gat_data, # Genes in GAT columns\n",
    "            num_tfs_in_raw=num_tfs_master, # TFs from master list\n",
    "            num_tissues_to_process=effective_num_tissues_for_edges,\n",
    "            raw_gat_data_dir=GAT_RAW_DATA_DIR,\n",
    "            gene_order_for_raw_alignment=final_gene_order_for_gat_cols, # Gene order for raw matrix alignment\n",
    "            edge_index_dir=GAT_EDGE_INDEX_DIR,\n",
    "            threshold_std_factor=GAT_INTERACTION_THRESHOLD_STD_FACTOR,\n",
    "            force_rebuild=args.force_edge_rebuild,\n",
    "            max_edges_per_tissue_approx=MAX_EDGES_PER_TISSUE_APPROX\n",
    "        )\n",
    "\n",
    "        # 5. Datasets & DataLoaders\n",
    "        log_message(\"\\n--- Step 5: Creating Datasets and DataLoaders ---\")\n",
    "        # PromoterGATDataset needs gene order from GAT data for mapping\n",
    "        full_dataset = PromoterGATDataset(all_sequences_encoded, all_gene_ids_for_samples, all_labels,\n",
    "                                          final_priors_for_dataset, final_gene_order_for_gat_cols)\n",
    "        # ... (Splitting logic and DataLoader creation remains the same)\n",
    "        dataset_size=len(full_dataset); indices=list(range(dataset_size)); np.random.seed(RANDOM_SEED); np.random.shuffle(indices)\n",
    "        test_split_idx=int(np.floor(TEST_SPLIT*dataset_size)); val_split_idx=test_split_idx+int(np.floor(VALIDATION_SPLIT*dataset_size))\n",
    "        train_indices = indices[val_split_idx:]; val_indices = indices[test_split_idx:val_split_idx]; test_indices = indices[:test_split_idx]\n",
    "        if not train_indices or not val_indices or not test_indices: raise ValueError(\"Dataset splitting resulted in empty sets.\")\n",
    "        train_dataset=Subset(full_dataset,train_indices); val_dataset=Subset(full_dataset,val_indices); test_dataset=Subset(full_dataset,test_indices)\n",
    "        log_message(f\"Dataset split: Train={len(train_dataset)}, Val={len(val_dataset)}, Test={len(test_dataset)}\")\n",
    "        num_workers = min(os.cpu_count() // 2 if os.cpu_count() is not None else 0, 4) if DEVICE.type=='cuda' else 0\n",
    "        drop_last_train = (len(train_dataset) % BATCH_SIZE == 1) # Avoid single-sample batch if it causes issues\n",
    "        train_loader = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=num_workers,pin_memory=(DEVICE.type=='cuda'),drop_last=drop_last_train)\n",
    "        val_loader = DataLoader(val_dataset,batch_size=BATCH_SIZE,shuffle=False,num_workers=num_workers,pin_memory=(DEVICE.type=='cuda'))\n",
    "        test_loader = DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=False,num_workers=num_workers,pin_memory=(DEVICE.type=='cuda'))\n",
    "\n",
    "\n",
    "        # 6. Initialize Model\n",
    "        log_message(\"\\n--- Step 6: Initializing BWAF Model ---\")\n",
    "        model = FullModel(\n",
    "            num_genes_nodes=initial_node_features_for_gat.shape[0], # num_genes_in_aligned_gat_data\n",
    "            initial_node_feature_dim=initial_node_features_for_gat.shape[1], # num_tfs_master\n",
    "            num_tissues_to_process=effective_num_tissues_for_edges, # Use actual number of tissues with edges\n",
    "            prior_dim=prior_dim,\n",
    "            embed_dim=EMBEDDING_DIM, num_attn_heads=NUM_ATTN_HEADS, transformer_ff_dim=TRANSFORMER_FF_DIM,\n",
    "            num_transformer_layers=NUM_TRANSFORMER_LAYERS, gat_hidden_dim=EMBEDDING_DIM, num_gat_layers=NUM_GAT_LAYERS,\n",
    "            gat_heads=GAT_HEADS, gat_final_heads=GAT_FINAL_HEADS, fusion_hidden_dim=FUSION_HIDDEN_DIM, dropout=DROPOUT_RATE\n",
    "        ).to(DEVICE)\n",
    "        total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        log_message(f\"Model Initialized. Trainable Params: {total_params:,}\")\n",
    "\n",
    "        # 7. Precompute GAT\n",
    "        log_message(\"\\n--- Step 7: Precomputing GAT Output ---\")\n",
    "        model.precompute_gat(initial_node_features_for_gat.to(DEVICE), edge_indices_list, DEVICE)\n",
    "        del initial_node_features_for_gat; # Free memory\n",
    "        if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "        # 8. Training Components\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=OPTIMIZER_WEIGHT_DECAY)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=5)\n",
    "\n",
    "        # 9. Train\n",
    "        log_message(\"\\n--- Step 8: Training Model ---\")\n",
    "        trained_model = train_model(model,train_loader,val_loader,criterion,optimizer,NUM_EPOCHS,DEVICE,scheduler=scheduler)\n",
    "        if trained_model is None: raise RuntimeError(\"Model training failed.\")\n",
    "\n",
    "        # 10. Evaluate\n",
    "        log_message(\"\\n--- Step 9: Evaluating Best Model ---\")\n",
    "        best_model_path_to_load = MODEL_SAVE_PATH\n",
    "        log_message(f\"Loading best model state from '{best_model_path_to_load}' for final evaluation.\")\n",
    "        if os.path.exists(best_model_path_to_load):\n",
    "            eval_model = FullModel( # Re-initialize structure\n",
    "                 num_genes_nodes=num_genes_in_aligned_gat_data, initial_node_feature_dim=num_tfs_master,\n",
    "                 num_tissues_to_process=effective_num_tissues_for_edges, prior_dim=prior_dim,\n",
    "                 embed_dim=EMBEDDING_DIM, num_attn_heads=NUM_ATTN_HEADS, transformer_ff_dim=TRANSFORMER_FF_DIM,\n",
    "                 num_transformer_layers=NUM_TRANSFORMER_LAYERS, gat_hidden_dim=EMBEDDING_DIM, num_gat_layers=NUM_GAT_LAYERS,\n",
    "                 gat_heads=GAT_HEADS, gat_final_heads=GAT_FINAL_HEADS, fusion_hidden_dim=FUSION_HIDDEN_DIM, dropout=DROPOUT_RATE\n",
    "            ).to(DEVICE)\n",
    "            try:\n",
    "                eval_model.load_state_dict(torch.load(best_model_path_to_load, map_location=DEVICE))\n",
    "                # Copy precomputed GAT output to the eval model instance\n",
    "                if trained_model.precomputed_gat_output is not None: # Use from model instance that was trained\n",
    "                    eval_model.precomputed_gat_output = trained_model.precomputed_gat_output\n",
    "                    eval_model.gat_device = trained_model.gat_device\n",
    "                else: # Fallback: re-precompute if not available on trained_model (should be)\n",
    "                     log_message(\"Re-precomputing GAT for loaded eval_model as it was not available from trained model instance.\")\n",
    "                     temp_initial_node_features, _ = load_processed_gat_data(GAT_PREPROCESSED_DIR, final_gene_order_from_gat_processing, master_tf_ids_final)\n",
    "                     temp_edge_indices_list = load_or_create_edge_indices(\n",
    "                        num_genes_in_aligned_gat_data, num_tfs_master, effective_num_tissues_for_edges, GAT_RAW_DATA_DIR, final_gene_order_from_gat_processing,\n",
    "                        GAT_EDGE_INDEX_DIR, GAT_INTERACTION_THRESHOLD_STD_FACTOR, False, MAX_EDGES_PER_TISSUE_APPROX\n",
    "                     )\n",
    "                     eval_model.precompute_gat(temp_initial_node_features.to(DEVICE), temp_edge_indices_list, DEVICE)\n",
    "                     del temp_initial_node_features, temp_edge_indices_list\n",
    "                     if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "            except Exception as e:\n",
    "                log_message(f\"Error loading best model state dict: {e}. Evaluating model from last epoch instead.\")\n",
    "                eval_model = trained_model # Fallback to last epoch model\n",
    "        else:\n",
    "            log_message(f\"Warning: Best model file '{best_model_path_to_load}' not found. Evaluating model from last epoch.\")\n",
    "            eval_model = trained_model\n",
    "\n",
    "        test_results = evaluate_model(eval_model, test_loader, criterion, DEVICE, results_csv_path=RESULTS_CSV_PATH)\n",
    "\n",
    "        script_end_time = time.time()\n",
    "        total_duration_seconds = script_end_time - script_start_time\n",
    "        log_message(f\"\\n--- Workflow Completed Successfully in {total_duration_seconds:.2f} seconds ({total_duration_seconds/3600:.2f} hours) ---\")\n",
    "\n",
    "    except FileNotFoundError as fnf_error:\n",
    "        log_message(f\"\\n--- WORKFLOW ERROR: FILE NOT FOUND ---\"); log_message(f\"Error: {fnf_error}\")\n",
    "        log_message(\"Please ensure all data paths in Section 2 are correct and files exist.\"); sys.exit(1)\n",
    "    except ValueError as val_error:\n",
    "        log_message(f\"\\n--- WORKFLOW ERROR: VALUE ERROR ---\"); log_message(f\"Error: {val_error}\")\n",
    "        import traceback; log_message(\"Traceback:\\n\" + traceback.format_exc()); sys.exit(1)\n",
    "    except RuntimeError as rt_error:\n",
    "        log_message(f\"\\n--- PYTORCH RUNTIME ERROR (often CUDA memory or tensor shape issues) ---\"); log_message(f\"Error: {rt_error}\")\n",
    "        import traceback; log_message(\"Traceback:\\n\" + traceback.format_exc()); sys.exit(1)\n",
    "    except Exception as main_error:\n",
    "        log_message(f\"\\n--- CRITICAL UNEXPECTED WORKFLOW ERROR ---\"); log_message(f\"Type: {type(main_error).__name__}\"); log_message(f\"Msg: {main_error}\")\n",
    "        import traceback; log_message(\"Traceback:\\n\" + traceback.format_exc()); sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38763bf9-8af8-498e-8287-a69c4af72780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c721302c-2628-4780-b532-1dbb7b7cc8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cf2d10-1cc6-4c50-947a-43bfdb8b6bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e2a03a-9427-499a-943b-5284ea7c2f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aaec21-b53c-4ded-b8b8-5ab55015fb72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6046cd6b-ef62-4c8c-8eb6-0741d8bf262a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d074eae3-e62f-419d-8ad7-8d42b734294e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8ad10a-ee55-46a9-9349-6655b447a280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d131b-6922-47bc-9d3b-16a972052caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbad854-97f4-4a27-9968-04e26827356c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79763f6-a58c-458d-b60d-345945297040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506c56d1-5b83-45e8-a2ae-68559fdca17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e551945d-e755-4f43-8673-496c6e16cd9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7732cc7-c265-45a2-805b-76d1b3cec388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f951b31f-0056-4f21-a02b-0a6037c107f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff8d9c-2a92-42b5-8407-5e1e7f911d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761de669-3ed2-4490-b6e2-25424c70f271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
